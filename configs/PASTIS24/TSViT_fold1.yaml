MODEL:
  architecture:  "TSViT"
  img_res: 24
  max_seq_len: 60
  num_channels: 11
  num_features: 16
  num_classes: 19
  ignore_background: False
  dropout: 0.2
  patch_size: 2
  dim: 128
  temporal_depth: 4
  spatial_depth: 4
  heads: 4
  pool: 'cls'
  dim_head: 32
  emb_dropout: 0.2
  scale_dim: 4


#MODEL:
#  architecture: "ConvBiRNN"
#  backbone: "ConvGRU"
#  shape_pattern: 'NTHWC'
#  img_res: 24
#  max_seq_len: 60
#  num_channels: 11
#  num_classes: 19
#  dropout: 0.
#


DATASETS:
  train:
    dataset: "PASTIS24_fold1"
    label_map:
    max_seq_len: 60
    batch_size: 4
    extra_data:
    num_workers: 0

  eval:
    dataset: "PASTIS24_fold1"
    label_map:
    max_seq_len: 60
    batch_size: 4
    extra_data:
    num_workers: 0

  test:
    dataset: "PASTIS24_fold1"
    label_map:
    max_seq_len: 60
    batch_size: 4
    extra_data:
    num_workers: 0

SOLVER:
  num_epochs: 100
  num_warmup_epochs: 10
  steps: (0, 80000)
  loss_function:  masked_cross_entropy
  class_weights:
  lr_scheduler: 'cosine'
  lr_base: 1e-3
  lr_min: 5e-6
  lr_start: 1e-8
  num_cycles: 1
  reset_lr: True   # resets lr to base value when loading pretrained model
  weight_decay: 0.001

CHECKPOINT:
  load_from_checkpoint:
  partial_restore: False
  save_path: 'C:/Users/vipuser/Desktop/pth/flod1/PASTIS/fold1_shijiankongjian'
  log_path: 'C:/Users/vipuser/Desktop/pth/flod1/PASTIS/flod1_shijiankongjian_logs1'
  train_metrics_steps: 250
  eval_steps: 2000
  save_steps: 20000000000
