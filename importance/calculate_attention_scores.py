#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ³¨æ„åŠ›åˆ†æ”¯å®šæ€§åˆ†æè„šæœ¬ï¼ˆä¿®æ”¹ç‰ˆï¼‰
ä¸»è¦ä¿®æ”¹ï¼š
1. æ·»åŠ é—¨æ§æƒé‡CSVä¿å­˜åŠŸèƒ½
2. æ·»åŠ é—¨æ§æƒé‡å¯è§†åŒ–åŠŸèƒ½
3. æ”¯æŒç©ºé—´æ¨¡å¼ä¸‹çš„é—¨æ§æƒé‡åˆ†æ
"""

import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from tqdm import tqdm
import sys
import torch.nn.functional as F
import matplotlib.gridspec as gridspec
from matplotlib.lines import Line2D
import warnings
import matplotlib as mpl

# è®¾ç½®å…¨å±€ç»˜å›¾æ ·å¼
mpl.rcParams['font.family'] = 'serif'
mpl.rcParams['font.size'] = 12
mpl.rcParams['axes.titlesize'] = 14
mpl.rcParams['axes.labelsize'] = 12
mpl.rcParams['xtick.labelsize'] = 10
mpl.rcParams['ytick.labelsize'] = 10
mpl.rcParams['legend.fontsize'] = 10
mpl.rcParams['figure.dpi'] = 300
mpl.rcParams['savefig.dpi'] = 300
plt.style.use('seaborn-whitegrid')

# å¿½ç•¥ç‰¹å®šè­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data import get_dataloaders
from data.PASTIS24.data_transforms import Normalize
from models import get_model
from utils.config_files_utils import read_yaml
from utils.torch_utils import get_device, load_from_checkpoint

# ===========================================
# ç›´æ¥è®¾ç½®è·¯å¾„å’Œå‚æ•°
# ===========================================

CFG_PATH = r"C:\Users\Think\Desktop\DeepSatModels-main\configs\PASTIS24\TSViT_fold5.yaml"
WEIGHTS_PATH = r"C:\Users\Think\Desktop\æ¨¡å‹\logs\é—¨æ§è‡ªé€‚åº”8684\best.pth"
SAVE_DIR = r"C:\Users\Think\Desktop\attention_analysis"
PICKLE_FILE = r"C:\Users\Think\Desktop\bq\bq_new_new\kuochong_30\64\total2\20369_1_0.pickle"
NUM_SAMPLES = 1
DEVICE_IDS = [0]
ANALYSIS_MODE = 'spatial'  # å¯é€‰ 'temporal' æˆ– 'spatial'


# ===========================================
# è¾…åŠ©å‡½æ•°
# ===========================================

def save_gate_weights(weights_data, save_dir, prefix, num_positions):
    """ä¿å­˜é—¨æ§æƒé‡åˆ°CSVæ–‡ä»¶"""
    os.makedirs(save_dir, exist_ok=True)

    # ç¡®ä¿æƒé‡æ•°æ®ä¸ä¸ºç©º
    if not weights_data:
        print("âš ï¸ è­¦å‘Š: æƒé‡æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜CSV")
        return

    for block_idx, block_data in enumerate(weights_data):
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        if 'attn' not in block_data or 'mamba' not in block_data:
            print(f"âš ï¸ å— {block_idx} ç¼ºå°‘æƒé‡æ•°æ®ï¼Œè·³è¿‡ä¿å­˜")
            continue

        # è·å–å½“å‰å—çš„æƒé‡æ•°æ®
        attn_weights = block_data['attn']
        mamba_weights = block_data['mamba']

        # ç¡®ä¿æ˜¯å¼ é‡
        if isinstance(attn_weights, torch.Tensor):
            attn_weights = attn_weights.numpy()
        if isinstance(mamba_weights, torch.Tensor):
            mamba_weights = mamba_weights.numpy()

        # æ£€æŸ¥å½¢çŠ¶
        if attn_weights.ndim > 1:
            # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            attn_weights = attn_weights[0]
        if mamba_weights.ndim > 1:
            mamba_weights = mamba_weights[0]

        # ç¡®ä¿é•¿åº¦æ­£ç¡®
        if len(attn_weights) < num_positions:
            # å¡«å……é›¶å€¼
            padded = np.zeros(num_positions)
            padded[:len(attn_weights)] = attn_weights
            attn_weights = padded
        elif len(attn_weights) > num_positions:
            attn_weights = attn_weights[:num_positions]

        if len(mamba_weights) < num_positions:
            padded = np.zeros(num_positions)
            padded[:len(mamba_weights)] = mamba_weights
            mamba_weights = padded
        elif len(mamba_weights) > num_positions:
            mamba_weights = mamba_weights[:num_positions]

        # åˆ›å»ºDataFrame
        df = pd.DataFrame({
            'position': range(num_positions),
            'attn_weight': attn_weights,
            'mamba_weight': mamba_weights
        })

        # ä¿å­˜CSV
        csv_path = os.path.join(save_dir, f"{prefix}_gate_weights_block_{block_idx}.csv")
        df.to_csv(csv_path, index=False)
        print(f"âœ… ä¿å­˜é—¨æ§æƒé‡CSV: {csv_path}")


def plot_gate_weights(weights_data, save_dir, prefix, num_positions, figsize=(10, 6)):
    """
    ç»˜åˆ¶é—¨æ§æƒé‡æŸ±çŠ¶å›¾ï¼ˆå¦‚æ‚¨æä¾›çš„å›¾ç‰‡æ ·å¼ï¼‰
    :param weights_data: é—¨æ§æƒé‡æ•°æ®
    :param save_dir: ä¿å­˜ç›®å½•
    :param prefix: æ–‡ä»¶åå‰ç¼€
    :param num_positions: ä½ç½®æ•°é‡
    :param figsize: å›¾ç‰‡å°ºå¯¸
    """
    os.makedirs(save_dir, exist_ok=True)

    # ç¡®ä¿æƒé‡æ•°æ®ä¸ä¸ºç©º
    if not weights_data:
        print("âš ï¸ è­¦å‘Š: æƒé‡æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")
        return

    for block_idx, block_data in enumerate(weights_data):
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        if 'attn' not in block_data or 'mamba' not in block_data:
            print(f"âš ï¸ å— {block_idx} ç¼ºå°‘æƒé‡æ•°æ®ï¼Œè·³è¿‡ç»˜å›¾")
            continue

        # æå–å½“å‰å—çš„æƒé‡
        attn_weights = block_data['attn']
        mamba_weights = block_data['mamba']

        # ç¡®ä¿æ˜¯å¼ é‡
        if isinstance(attn_weights, torch.Tensor):
            attn_weights = attn_weights.numpy()
        if isinstance(mamba_weights, torch.Tensor):
            mamba_weights = mamba_weights.numpy()

        # æ£€æŸ¥å½¢çŠ¶
        if attn_weights.ndim > 1:
            # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            attn_weights = attn_weights[0]
        if mamba_weights.ndim > 1:
            mamba_weights = mamba_weights[0]

        # ç¡®ä¿é•¿åº¦æ­£ç¡®
        if len(attn_weights) > num_positions:
            attn_weights = attn_weights[:num_positions]
        if len(mamba_weights) > num_positions:
            mamba_weights = mamba_weights[:num_positions]

        # åˆ›å»ºä¸“ä¸šå­¦æœ¯å›¾è¡¨
        fig, ax = plt.subplots(figsize=figsize, dpi=300)

        # è®¾ç½®ä¸“ä¸šé…è‰²
        attention_color = '#4e79a7'  # æ·±è“è‰²
        mamba_color = '#f28e2b'  # æ©™è‰²

        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        positions = np.arange(num_positions)
        bar_width = 0.4

        # ç»˜åˆ¶æ³¨æ„åŠ›æƒé‡
        ax.bar(
            positions,
            attn_weights,
            width=bar_width,
            color=attention_color,
            edgecolor='black',
            linewidth=0.7,
            alpha=0.9,
            label='Attention'
        )

        # ç»˜åˆ¶Mambaæƒé‡
        ax.bar(
            positions + bar_width,
            mamba_weights,
            width=bar_width,
            color=mamba_color,
            edgecolor='black',
            linewidth=0.7,
            alpha=0.9,
            label='Mamba'
        )

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (attn_w, mamba_w) in enumerate(zip(attn_weights, mamba_weights)):
            ax.text(
                i, attn_w + 0.005, f"{attn_w:.3f}",
                ha='center', fontsize=8, fontweight='bold'
            )
            ax.text(
                i + bar_width, mamba_w + 0.005, f"{mamba_w:.3f}",
                ha='center', fontsize=8, fontweight='bold'
            )

        # æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(f'Gate Weights - Block {block_idx + 1}', fontsize=14, pad=15)
        ax.set_xlabel('Patch Position', fontsize=12, labelpad=10)
        ax.set_ylabel('Gate Weight Value', fontsize=12, labelpad=10)
        ax.set_xticks(positions + bar_width / 2)
        ax.set_xticklabels([f'{i}' for i in range(num_positions)], fontsize=10)

        # è®¾ç½®Yè½´èŒƒå›´
        max_val = max(np.max(attn_weights), np.max(mamba_weights))
        ax.set_ylim(0, max_val * 1.25 if max_val > 0 else 1.0)

        # æ·»åŠ å›¾ä¾‹å’Œç½‘æ ¼
        ax.legend(fontsize=10, frameon=True, shadow=True, loc='upper right')
        ax.grid(axis='y', linestyle='--', alpha=0.7)

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        img_path = os.path.join(save_dir, f"{prefix}_gate_weights_block_{block_idx + 1}.png")
        plt.savefig(img_path, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜é—¨æ§æƒé‡å›¾: {img_path}")


def custom_normalize(data, mean, std):
    """æ‰‹åŠ¨åº”ç”¨å½’ä¸€åŒ–å¤„ç†ï¼Œä¿æŒæ—¶é—´æ­¥é•¿ä¸å˜"""
    mean = mean.squeeze().astype(np.float32)
    std = std.squeeze().astype(np.float32)

    if data.ndim == 4:  # (T, C, H, W)
        mean = mean.reshape(1, -1, 1, 1)
        std = std.reshape(1, -1, 1, 1)
    elif data.ndim == 3:  # (C, H, W)
        mean = mean.reshape(-1, 1, 1)
        std = std.reshape(-1, 1, 1)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç»´åº¦: {data.ndim}")

    normalized = (data - mean) / std
    return normalized.astype(np.float32)


def prepare_model_input(normalized_img, doys):
    """
    å‡†å¤‡ç¬¦åˆæ¨¡å‹è¾“å…¥çš„å¼ é‡
    """
    doy_normalized = doys / 365.0
    doy_channel = doy_normalized[:, np.newaxis, np.newaxis, np.newaxis]
    doy_channel = np.broadcast_to(
        doy_channel,
        (doy_normalized.shape[0], 1, normalized_img.shape[2], normalized_img.shape[3])
    )

    model_input = np.concatenate([normalized_img, doy_channel], axis=1)
    return model_input.astype(np.float32)


def process_time_features(xt, device):
    """å¤„ç†æ—¶é—´ç‰¹å¾ï¼Œé¿å…ç´¢å¼•é”™è¯¯"""
    xt = torch.clamp(xt * 365.0001, 0, 365)
    xt = xt.to(torch.int64)
    max_val = xt.max().item()
    if max_val >= 366:
        print(f"âš ï¸ è­¦å‘Š: æœ€å¤§æ—¶é—´ç‰¹å¾å€¼ {max_val} è¶…è¿‡365ï¼Œå°†è¢«è£å‰ª")
        xt = torch.clamp(xt, 0, 365)
    xt = F.one_hot(xt, num_classes=366).to(torch.float32)
    return xt


# ===========================================
# äºŒéƒ¨å›¾å¯è§†åŒ–å‡½æ•°ï¼ˆä¿®æ”¹ç‰ˆï¼‰
# ===========================================

def plot_attention_bipartite(attention_matrix, save_path, block_idx, figsize=(12, 6)):
    """
    ç»˜åˆ¶ä¿®æ”¹åçš„äºŒéƒ¨å›¾ï¼ˆå‚ç›´å¸ƒå±€ï¼‰ï¼Œè™šåŒ–ä¸é‡è¦çš„çº¿å¹¶çªå‡ºé‡è¦èŠ‚ç‚¹
    :param attention_matrix: æ³¨æ„åŠ›çŸ©é˜µ [query_len, key_len]
    :param save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
    :param block_idx: å½“å‰å—ç´¢å¼•
    :param figsize: å›¾åƒå¤§å°
    """
    T = attention_matrix.shape[0]  # æ—¶é—´æ­¥æ•°é‡

    # åˆ›å»ºç”»å¸ƒ
    fig = plt.figure(figsize=figsize)
    ax = fig.add_subplot(111)

    # 1. è®¡ç®—èŠ‚ç‚¹é‡è¦æ€§ï¼ˆåŸºäºæ³¨æ„åŠ›æƒé‡ï¼‰
    # è¾“å…¥èŠ‚ç‚¹ï¼ˆKeyï¼‰é‡è¦æ€§ = æ¯åˆ—çš„å’Œï¼ˆæ‰€æœ‰è¾“å‡ºèŠ‚ç‚¹å¯¹å…¶çš„å…³æ³¨åº¦ï¼‰
    key_importance = attention_matrix.sum(axis=0)
    # è¾“å‡ºèŠ‚ç‚¹ï¼ˆQueryï¼‰é‡è¦æ€§ = æ¯è¡Œçš„å’Œï¼ˆè¯¥èŠ‚ç‚¹å¯¹æ‰€æœ‰è¾“å…¥èŠ‚ç‚¹çš„å…³æ³¨åº¦ï¼‰
    query_importance = attention_matrix.sum(axis=1)

    # å½’ä¸€åŒ–é‡è¦æ€§åˆ†æ•°ï¼ˆç”¨äºèŠ‚ç‚¹å¤§å°ï¼‰
    key_importance_norm = (key_importance - key_importance.min()) / (key_importance.max() - key_importance.min() + 1e-8)
    query_importance_norm = (query_importance - query_importance.min()) / (
            query_importance.max() - query_importance.min() + 1e-8)

    # èŠ‚ç‚¹å¤§å°èŒƒå›´ [50, 300]
    min_node_size = 50
    max_node_size = 300
    key_sizes = min_node_size + (max_node_size - min_node_size) * key_importance_norm
    query_sizes = min_node_size + (max_node_size - min_node_size) * query_importance_norm

    # 2. ç¡®å®šé‡è¦èŠ‚ç‚¹ï¼ˆé‡è¦æ€§å¤§äºå¹³å‡å€¼ï¼‰
    important_key_indices = np.where(key_importance > key_importance.mean())[0]
    important_query_indices = np.where(query_importance > query_importance.mean())[0]

    print(f"é‡è¦è¾“å…¥èŠ‚ç‚¹: {important_key_indices}")
    print(f"é‡è¦è¾“å‡ºèŠ‚ç‚¹: {important_query_indices}")

    # 3. èŠ‚ç‚¹ä½ç½®è®¡ç®—ï¼ˆå‚ç›´å¸ƒå±€ï¼‰
    x_pos_top = np.linspace(0, 1, T)  # é¡¶éƒ¨èŠ‚ç‚¹xåæ ‡ï¼ˆè¾“å…¥èŠ‚ç‚¹ï¼‰
    x_pos_bottom = np.linspace(0, 1, T)  # åº•éƒ¨èŠ‚ç‚¹xåæ ‡ï¼ˆè¾“å‡ºèŠ‚ç‚¹ï¼‰

    # 4. ç»˜åˆ¶æ‰€æœ‰èŠ‚ç‚¹
    # æ™®é€šèŠ‚ç‚¹ï¼ˆç°è‰²ï¼‰
    all_key_nodes = ax.scatter(
        x_pos_top, [1] * T,
        s=key_sizes,
        c='lightgray',
        edgecolors='k',
        alpha=0.7,
        label='è¾“å…¥èŠ‚ç‚¹ (Key)'
    )

    all_query_nodes = ax.scatter(
        x_pos_bottom, [0] * T,
        s=query_sizes,
        c='lightgray',
        edgecolors='k',
        alpha=0.7,
        label='è¾“å‡ºèŠ‚ç‚¹ (Query)'
    )

    # çªå‡ºé‡è¦èŠ‚ç‚¹ï¼ˆå½©è‰²ï¼‰
    if len(important_key_indices) > 0:
        ax.scatter(
            x_pos_top[important_key_indices], [1] * len(important_key_indices),
            s=key_sizes[important_key_indices],
            c='skyblue',
            edgecolors='k',
            alpha=1.0,
            zorder=10  # ç¡®ä¿é‡è¦èŠ‚ç‚¹åœ¨æœ€ä¸Šå±‚
        )

    if len(important_query_indices) > 0:
        ax.scatter(
            x_pos_bottom[important_query_indices], [0] * len(important_query_indices),
            s=query_sizes[important_query_indices],
            c='lightblue',
            edgecolors='k',
            alpha=1.0,
            zorder=10  # ç¡®ä¿é‡è¦èŠ‚ç‚¹åœ¨æœ€ä¸Šå±‚
        )

    # 5. æ·»åŠ èŠ‚ç‚¹æ ‡ç­¾ï¼ˆåªæ ‡è®°é‡è¦èŠ‚ç‚¹ï¼‰
    # for i in range(T):
    #     # è¾“å…¥èŠ‚ç‚¹ï¼ˆé¡¶éƒ¨ï¼‰
    #     if i in important_key_indices:
    #         ax.text(
    #             x_pos_top[i], 1.05, '',
    #             ha='center', va='bottom', fontsize=10, fontweight='bold',
    #             bbox=dict(facecolor='skyblue', alpha=0.8, pad=2, edgecolor='k')
    #         )
    #     # è¾“å‡ºèŠ‚ç‚¹ï¼ˆåº•éƒ¨ï¼‰
    #     if i in important_query_indices:
    #         ax.text(
    #             x_pos_bottom[i], -0.05, '',
    #             ha='center', va='top', fontsize=10, fontweight='bold',
    #             bbox=dict(facecolor='skyblue', alpha=0.8, pad=2, edgecolor='k')
    #         )

    # 6. ç»˜åˆ¶è¾¹ï¼ˆç”¨é€æ˜åº¦è¡¨ç¤ºæƒé‡ï¼‰
    max_weight = np.max(attention_matrix)
    min_weight = np.min(attention_matrix[attention_matrix > 0])

    # æ‰¾å‡ºæœ€å¤§æ³¨æ„åŠ›ä½ç½®
    max_attention_idx = np.unravel_index(np.argmax(attention_matrix), attention_matrix.shape)

    # è®¡ç®—æ‰€æœ‰è¾¹çš„æƒé‡é˜ˆå€¼
    weight_threshold = max_weight * 0.05  # åªæ˜¾ç¤ºå¤§äºæœ€å¤§æƒé‡10%çš„è¾¹

    for i in range(T):  # queryç´¢å¼• (è¾“å‡ºèŠ‚ç‚¹ï¼Œåº•éƒ¨)
        for j in range(T):  # keyç´¢å¼• (è¾“å…¥èŠ‚ç‚¹ï¼Œé¡¶éƒ¨)
            weight = attention_matrix[i, j]

            # åªç»˜åˆ¶æ˜¾è‘—çš„è¾¹
            if weight > weight_threshold:
                # è®¡ç®—å½’ä¸€åŒ–æƒé‡ï¼ˆ0-1èŒƒå›´ï¼‰
                norm_weight = (weight - min_weight) / (max_weight - min_weight + 1e-8)
                linewidth = 0.5 + 2.5 * norm_weight

                # æ ‡è®°æœ€å¤§æ³¨æ„åŠ›è¾¹
                is_max = (i, j) == max_attention_idx

                # åˆ¤æ–­æ˜¯å¦æ˜¯é‡è¦èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥
                is_important_edge = (j in important_key_indices) and (i in important_query_indices)

                if is_max:
                    # æœ€å¤§æ³¨æ„åŠ›è¾¹ - çº¢è‰²
                    color = 'lightblue'
                    alpha = 0.8
                    linestyle = '-'
                elif is_important_edge:
                    # é‡è¦èŠ‚ç‚¹ä¹‹é—´çš„è¾¹ - è“è‰²
                    color = 'lightblue'
                    alpha = 0.8
                    linestyle = '-'
                else:
                    # æ™®é€šè¾¹ - æµ…ç°è‰²ï¼ŒåŠé€æ˜
                    color = 'lightgray'
                    alpha = 0.3
                    linestyle = '--'  # è™šçº¿è¡¨ç¤ºä¸é‡è¦

                # ç»˜åˆ¶è¾¹ï¼ˆä»é¡¶éƒ¨èŠ‚ç‚¹åˆ°åº•éƒ¨èŠ‚ç‚¹ï¼‰
                ax.plot(
                    [x_pos_top[j], x_pos_bottom[i]],
                    [1, 0],
                    linewidth=linewidth,
                    alpha=alpha,
                    color=color,
                    linestyle=linestyle,
                    zorder=1 if is_important_edge or is_max else 0
                )

    # 7. æ·»åŠ å›¾ä¾‹
    # legend_elements = [
    #     Line2D([0], [0], color='skyblue', marker='o', markersize=8, label='é‡è¦è¾“å…¥èŠ‚ç‚¹', linestyle='None'),
    #     Line2D([0], [0], color='lightgreen', marker='o', markersize=8, label='é‡è¦è¾“å‡ºèŠ‚ç‚¹', linestyle='None'),
    #     Line2D([0], [0], color='lightgray', marker='o', markersize=8, label='æ™®é€šèŠ‚ç‚¹', linestyle='None'),
    #     Line2D([0], [0], color='red', linewidth=2, label='æœ€å¤§æ³¨æ„åŠ›è¾¹'),
    #     Line2D([0], [0], color='blue', linewidth=2, label='é‡è¦èŠ‚ç‚¹é—´è¿æ¥'),
    #     Line2D([0], [0], color='lightgray', linewidth=1, linestyle='--', label='æ™®é€šè¿æ¥')
    # ]

    # ax.legend(
    #     handles=legend_elements,
    #     loc='upper center',
    #     bbox_to_anchor=(0.5, -0.1),
    #     ncol=3,
    #     fontsize=9
    # )

    ax.set_xlim(-0.1, 1.1)
    ax.set_ylim(-0.2, 1.2)
    # ax.set_title(f'æ³¨æ„åŠ›äºŒéƒ¨å›¾ - å— {block_idx}', fontsize=16, pad=20)
    ax.axis('off')

    # ä¿å­˜å›¾åƒ
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"âœ… ä¿å­˜äºŒéƒ¨å›¾: {save_path}")
    return save_path


# ===========================================
# ä¿®æ”¹åçš„å‰å‘ä¼ æ’­å‡½æ•°ï¼ˆæ•è·æ³¨æ„åŠ›å¾—åˆ†ï¼‰
# ===========================================

def modified_forward_with_attention(inputs, net, mode='temporal'):
    """
    ä¿®æ”¹åçš„æ¨¡å‹å‰å‘ä¼ æ’­å‡½æ•°ï¼Œæ•è·æ³¨æ„åŠ›å¾—åˆ†
    è¿”å›ï¼š
    - logits: æ¨¡å‹è¾“å‡º
    - attention_scores: å„å±‚çš„æ³¨æ„åŠ›å¾—åˆ†åˆ—è¡¨
    """
    # æå–è¾“å…¥å½¢çŠ¶
    B, T, C, H, W = inputs.shape
    inputs = inputs.float()

    # æå–æ—¶é—´ç‰¹å¾
    xt = inputs[:, :, -1, 0, 0]
    xt = process_time_features(xt, inputs.device)
    xt = xt.reshape(-1, 366)

    # åº”ç”¨æ—¶é—´ä½ç½®åµŒå…¥
    temporal_pos_embedding = net.to_temporal_embedding_input(xt).reshape(B, T, net.dim)

    # å‡†å¤‡patchåµŒå…¥
    x = inputs[:, :, :-1]  # ç§»é™¤æ—¶é—´ç‰¹å¾é€šé“

    # ç¡®ä¿ç©ºé—´ç»´åº¦èƒ½è¢«patch_sizeæ•´é™¤
    assert H % net.patch_size == 0, f"é«˜åº¦ {H} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"
    assert W % net.patch_size == 0, f"å®½åº¦ {W} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"

    # è®¡ç®—patchæ•°é‡
    num_patches_h = H // net.patch_size
    num_patches_w = W // net.patch_size
    num_patches = num_patches_h * num_patches_w

    # æ‰‹åŠ¨å®ç°é‡æ’æ“ä½œ
    x = x.unfold(3, net.patch_size, net.patch_size)
    x = x.unfold(4, net.patch_size, net.patch_size)
    x = x.permute(0, 3, 4, 1, 2, 5, 6)
    x = x.reshape(B * num_patches_h * num_patches_w, T, 20 * net.patch_size * net.patch_size)

    # åº”ç”¨çº¿æ€§å˜æ¢
    x = net.to_patch_embedding[1](x)

    # æ·»åŠ æ—¶é—´ä½ç½®åµŒå…¥
    x = x.reshape(B, num_patches, T, net.dim)
    x += temporal_pos_embedding.unsqueeze(1)
    x = x.reshape(B * num_patches, T, net.dim)

    # æ·»åŠ æ—¶é—´token
    cls_temporal_tokens = net.temporal_token.repeat(B * num_patches, 1, 1)
    x = torch.cat((cls_temporal_tokens, x), dim=1)

    # æ ¹æ®æ¨¡å¼è®¾ç½®æ³¨æ„åŠ›æ•è·
    if mode == 'temporal':
        # æ—¶é—´å˜æ¢å™¨ - æ•è·æ³¨æ„åŠ›å¾—åˆ†
        for block in net.temporal_transformer.layers:
            if hasattr(block, 'attn'):
                block.attn.return_attention = True  # å¯ç”¨æ³¨æ„åŠ›æ•è·
        x = net.temporal_transformer(x)

        # æ”¶é›†æ—¶é—´æ³¨æ„åŠ›å¾—åˆ†
        attention_scores_list = []
        for block in net.temporal_transformer.layers:
            if hasattr(block, 'attention_scores') and block.attention_scores is not None:
                attention_scores_list.append(block.attention_scores)
    else:
        # è·³è¿‡æ—¶é—´æ³¨æ„åŠ›æ•è·
        x = net.temporal_transformer(x)
        attention_scores_list = []

    # ç©ºé—´å˜æ¢å™¨
    x = x[:, :net.num_classes]
    x = x.reshape(B, num_patches, net.num_classes, net.dim)
    x = x.permute(0, 2, 1, 3)
    x = x.reshape(B * net.num_classes, num_patches, net.dim)

    # ç¡®ä¿ç©ºé—´ä½ç½®åµŒå…¥å¤§å°åŒ¹é…
    space_pos_embedding = net.space_pos_embedding[:, :num_patches] if net.space_pos_embedding.shape[
                                                                          1] > num_patches else net.space_pos_embedding
    x += space_pos_embedding

    # åº”ç”¨dropout
    if hasattr(net, 'dropout'):
        x = net.dropout(x)

    # æ ¹æ®æ¨¡å¼è®¾ç½®ç©ºé—´æ³¨æ„åŠ›æ•è·
    if mode == 'spatial':
        # è®¾ç½®ç©ºé—´transformerçš„å—ä»¥æ•è·æ³¨æ„åŠ›
        for block in net.space_transformer.layers:
            if hasattr(block, 'attn'):
                block.attn.return_attention = True
        x = net.space_transformer(x)

        # æ”¶é›†ç©ºé—´æ³¨æ„åŠ›å¾—åˆ†
        attention_scores_list = []
        for block in net.space_transformer.layers:
            if hasattr(block, 'attention_scores') and block.attention_scores is not None:
                attention_scores_list.append(block.attention_scores)
    else:
        # è·³è¿‡ç©ºé—´æ³¨æ„åŠ›æ•è·
        x = net.space_transformer(x)

    # MLPå¤´éƒ¨
    x = net.mlp_head(x.reshape(-1, net.dim))

    # é‡å¡‘è¾“å‡º
    x = x.reshape(B, net.num_classes, num_patches, net.patch_size ** 2)
    x = x.permute(0, 2, 3, 1)
    x = x.reshape(B, num_patches_h, num_patches_w, net.patch_size, net.patch_size, net.num_classes)
    x = x.permute(0, 1, 3, 2, 4, 5)
    x = x.reshape(B, num_patches_h * net.patch_size, num_patches_w * net.patch_size, net.num_classes)
    x = x.permute(0, 3, 1, 2)
    return x, attention_scores_list


# ===========================================
# è®¡ç®—æ¯å±‚ç©ºé—´å—é‡è¦æ€§
# ===========================================

def compute_spatial_block_importance_per_layer(attention_scores_list, num_blocks=16):
    """
    ä¸ºæ¯ä¸€å±‚è®¡ç®—ç©ºé—´å—é‡è¦æ€§
    :param attention_scores_list: ç©ºé—´æ³¨æ„åŠ›å¾—åˆ†åˆ—è¡¨ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰
    :param num_blocks: ç©ºé—´å—æ•°é‡ï¼ˆé»˜è®¤16ï¼‰
    :return: æ¯å±‚çš„é‡è¦æ€§å‘é‡åˆ—è¡¨
    """
    block_importance_per_layer = []

    for layer_idx, attention_scores in enumerate(attention_scores_list):
        print(f"è®¡ç®—ç¬¬ {layer_idx + 1} å±‚ç©ºé—´å—é‡è¦æ€§...")

        # å¤„ç†å¤šå¤´æ³¨æ„åŠ› [batch, heads, query_len, key_len]
        if attention_scores.dim() == 4:
            # å–ç¬¬ä¸€ä¸ªæ ·æœ¬ã€æ‰€æœ‰å¤´çš„å¹³å‡
            avg_attention = attention_scores.mean(dim=1)[0]  # [query_len, key_len]

            # è®¡ç®—æ¯ä¸ªå—ä½œä¸ºkeyè¢«å…³æ³¨çš„ç¨‹åº¦ï¼ˆåˆ—å’Œï¼‰
            block_importance = avg_attention.sum(dim=0).detach().cpu().numpy()

            # ç¡®ä¿é•¿åº¦æ­£ç¡®
            if len(block_importance) < num_blocks:
                block_importance = np.pad(block_importance, (0, num_blocks - len(block_importance)),
                                          mode='constant', constant_values=0)
            elif len(block_importance) > num_blocks:
                block_importance = block_importance[:num_blocks]

            block_importance_per_layer.append(block_importance)
        else:
            print(f"âš ï¸ ç¬¬ {layer_idx + 1} å±‚: ä¸æ”¯æŒçš„æ³¨æ„åŠ›ç»´åº¦ {attention_scores.dim()}")
            # æ·»åŠ ä¸€ä¸ªNaNå‘é‡
            block_importance_per_layer.append(np.full(num_blocks, np.nan))

    return block_importance_per_layer


# ===========================================
# æ³¨æ„åŠ›å¾—åˆ†å¯è§†åŒ–
# ===========================================

def plot_temporal_attention(attention_scores, save_dir, block_idx, input_series=None):
    """å¤„ç†æ—¶é—´æ³¨æ„åŠ›çŸ©é˜µ"""
    print(f"å— {block_idx} åŸå§‹æ—¶é—´æ³¨æ„åŠ›å¾—åˆ†å½¢çŠ¶: {attention_scores.shape}")

    # å¤„ç†å¤šå¤´æ³¨æ„åŠ› [batch, heads, query_len, key_len]
    if attention_scores.dim() == 4:
        # å–ç¬¬ä¸€ä¸ªæ ·æœ¬ã€æ‰€æœ‰å¤´çš„å¹³å‡
        avg_attention = attention_scores.mean(dim=1)[0]  # [query_len, key_len]
        print(f"å¹³å‡æ³¨æ„åŠ›å½¢çŠ¶: {avg_attention.shape}")

        # æå–æ—¶é—´æ­¥éƒ¨åˆ† (å21Ã—21)
        num_timesteps = 21
        timestep_attention = avg_attention[-num_timesteps:, -num_timesteps:]
        print(f"æ—¶é—´æ­¥æ³¨æ„åŠ›å½¢çŠ¶: {timestep_attention.shape}")

        # è½¬æ¢ä¸ºnumpy
        timestep_attention = timestep_attention.detach().cpu().numpy()

        # ä¿å­˜CSV
        csv_path = os.path.join(save_dir, f"timestep_attention_block_{block_idx}.csv")
        pd.DataFrame(timestep_attention).to_csv(csv_path, index=False)

        # ç»˜åˆ¶çƒ­åŠ›å›¾ï¼ˆä»…æ—¶é—´æ­¥ï¼‰
        plt.figure(figsize=(10, 8))
        ax = sns.heatmap(timestep_attention, annot=False, cmap="viridis", cbar=True, square=True,
                         annot_kws={"size": 16})
        # plt.title(f'æ—¶é—´æ­¥æ³¨æ„åŠ›çƒ­åŠ›å›¾ - å— {block_idx}', fontsize=16)
        plt.xlabel("observation time t_out", fontsize=20)
        plt.ylabel("observation time t_in", fontsize=20)
        # ä¿®æ”¹åˆ»åº¦å­—ä½“å¤§å°
        ax.tick_params(axis='x', labelsize=16)  # Xè½´åˆ»åº¦
        ax.tick_params(axis='y', labelsize=16)  # Yè½´åˆ»åº¦

        cbar = ax.collections[0].colorbar
        cbar.ax.tick_params(labelsize=16)  # é¢œè‰²æ¡åˆ»åº¦

        img_path = os.path.join(save_dir, f"timestep_attention_heatmap_block_{block_idx}.png")
        plt.savefig(img_path, dpi=400, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜æ—¶é—´æ­¥æ³¨æ„åŠ›å›¾: {img_path} (å½¢çŠ¶: {timestep_attention.shape})")

        # ç»˜åˆ¶äºŒéƒ¨å›¾ï¼ˆä¿®æ”¹ä¸ºå‚ç›´å¸ƒå±€ï¼‰
        bipartite_path = os.path.join(save_dir, f"bipartite_block_{block_idx}.png")
        plot_attention_bipartite(
            timestep_attention,
            bipartite_path,
            block_idx
        )
        print(f"âœ… äºŒéƒ¨å›¾å·²ä¿å­˜åˆ°: {bipartite_path}")

        return csv_path, img_path

    else:
        print(f"âš ï¸ ä¸æ”¯æŒçš„æ³¨æ„åŠ›ç»´åº¦: {attention_scores.dim()}")
        return None, None


def plot_spatial_attention(attention_scores, save_dir, block_idx):
    print(f"å— {block_idx} åŸå§‹ç©ºé—´æ³¨æ„åŠ›å¾—åˆ†å½¢çŠ¶: {attention_scores.shape}")

    if attention_scores.dim() == 4:
        avg_attention = attention_scores.mean(dim=1)[0].detach().cpu().numpy()

        csv_path = os.path.join(save_dir, f"spatial_attention_block_{block_idx}.csv")
        pd.DataFrame(avg_attention).to_csv(csv_path, index=False)

        plt.figure(figsize=(10, 8))
        ax = sns.heatmap(avg_attention, annot=False, cmap="Reds", cbar=True, square=True)

        # è®¾ç½®æ ‡é¢˜å’Œè½´æ ‡ç­¾å­—ä½“å¤§å°
        # plt.title(f"ç©ºé—´æ³¨æ„åŠ›çƒ­åŠ›å›¾ - å— {block_idx}", fontsize=18)
        plt.xlabel("Key", fontsize=20)
        plt.ylabel("Query", fontsize=20)

        # è®¾ç½®åˆ»åº¦å­—ä½“å¤§å°
        ax.tick_params(axis='x', labelsize=20)
        ax.tick_params(axis='y', labelsize=20)

        # è®¾ç½®é¢œè‰²æ¡å­—ä½“å¤§å°
        cbar = ax.collections[0].colorbar
        cbar.ax.tick_params(labelsize=20)

        img_path = os.path.join(save_dir, f"spatial_attention_heatmap_block_{block_idx}.png")
        plt.tight_layout()
        plt.savefig(img_path, dpi=500, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜ç©ºé—´æ³¨æ„åŠ›å›¾: {img_path} (å½¢çŠ¶: {avg_attention.shape})")

        return csv_path, img_path
    else:
        print(f"âš ï¸ ä¸æ”¯æŒçš„æ³¨æ„åŠ›ç»´åº¦: {attention_scores.dim()}")
        return None, None

def plot_attention_over_time(attention_scores, save_dir, block_idx):
    """ç»˜åˆ¶éšæ—¶é—´å˜åŒ–çš„æ³¨æ„åŠ›å¾—åˆ†ï¼ˆä»…é€‚ç”¨äºæ—¶é—´åˆ†æï¼‰"""
    # ç¡®å®šæ—¶é—´æ­¥æ•°é‡
    num_timesteps = 21  # æ ¹æ®æ‚¨çš„æ•°æ®

    # è®¡ç®—å®é™…æ—¶é—´æ­¥çš„èµ·å§‹ä½ç½®
    class_tokens_count = 4  # ç±»åˆ«tokenæ•°é‡
    timestep_start_idx = class_tokens_count  # æ—¶é—´æ­¥ä»ç¬¬4ä¸ªä½ç½®å¼€å§‹

    # æå–ç¬¬ä¸€ä¸ªç±»åˆ«tokenå¯¹æ—¶é—´æ­¥çš„æ³¨æ„åŠ›
    if attention_scores.dim() == 4:  # [batch, heads, query_len, key_len]
        # å–ç¬¬ä¸€ä¸ªæ ·æœ¬ã€ç¬¬ä¸€ä¸ªæ³¨æ„åŠ›å¤´
        cls_attention = attention_scores[0, 0, 0, timestep_start_idx:timestep_start_idx + num_timesteps]
    elif attention_scores.dim() == 3:  # [heads, query_len, key_len]
        cls_attention = attention_scores[0, 0, timestep_start_idx:timestep_start_idx + num_timesteps]
    elif attention_scores.dim() == 2:  # [query_len, key_len]
        cls_attention = attention_scores[0, timestep_start_idx:timestep_start_idx + num_timesteps]
    else:
        print(f"âš ï¸ ä¸æ”¯æŒçš„æ³¨æ„åŠ›ç»´åº¦: {attention_scores.dim()}")
        return None

    cls_attention = cls_attention.detach().cpu().numpy()

    # ç¡®ä¿é•¿åº¦æ­£ç¡®
    if len(cls_attention) != num_timesteps:
        print(f"âš ï¸ æ—¶é—´æ­¥æ•°é‡ä¸åŒ¹é…: æœŸæœ›{num_timesteps}, å®é™…{len(cls_attention)}")
        return None

    # åˆ›å»ºæ—¶é—´åºåˆ—
    time_steps = np.arange(num_timesteps)

    # ç»˜åˆ¶æŠ˜çº¿å›¾
    plt.figure(figsize=(12, 6))
    plt.plot(time_steps, cls_attention, marker='o', linestyle='-', color='b')
    # plt.title(f'CLS Tokenå¯¹æ—¶é—´æ­¥çš„æ³¨æ„åŠ› - å— {block_idx}', fontsize=16)
    plt.xlabel('observation time t')
    plt.ylabel('CLS attention scores')
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.xticks(np.arange(0, num_timesteps, step=1))

    # ä¿å­˜å›¾åƒ
    img_path = os.path.join(save_dir, f"cls_attention_block_{block_idx}.png")
    plt.savefig(img_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜CLSæ³¨æ„åŠ›å›¾: {img_path}")

    return img_path


# ===========================================
# ä¸»å‡½æ•°ï¼ˆä¿®æ”¹ç‰ˆï¼Œæ·»åŠ é—¨æ§æƒé‡ä¿å­˜å’Œå¯è§†åŒ–ï¼‰
# ===========================================

def main():
    global ANALYSIS_MODE

    print("=" * 50)
    print(f"æ¨¡å‹é…ç½®æ–‡ä»¶: {CFG_PATH}")
    print(f"æ¨¡å‹æƒé‡æ–‡ä»¶: {WEIGHTS_PATH}")
    print(f"ç»“æœä¿å­˜ç›®å½•: {SAVE_DIR}")
    print(f"ä½¿ç”¨è®¾å¤‡: {'GPU' if DEVICE_IDS else 'CPU'} {DEVICE_IDS}")
    print(f"åˆ†ææ¨¡å¼: {ANALYSIS_MODE}")
    print("=" * 50)

    # 0. è®¾å¤‡è®¾ç½®
    device = get_device(DEVICE_IDS, allow_cpu=True)

    # 1. åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(SAVE_DIR, exist_ok=True)
    attention_dir = os.path.join(SAVE_DIR, f"{ANALYSIS_MODE}_attention_scores")
    os.makedirs(attention_dir, exist_ok=True)
    print(f"ğŸ“ æ³¨æ„åŠ›åˆ†æç»“æœå°†ä¿å­˜åœ¨: {attention_dir}")

    # 2. è¯»å–é…ç½®
    config = read_yaml(CFG_PATH)
    config["local_device_ids"] = DEVICE_IDS

    # 3. åˆ›å»ºä¸´æ—¶dataloaderä»¥è·å–å½’ä¸€åŒ–å‚æ•°
    print("ğŸ“Š ç»Ÿè®¡è®­ç»ƒé›†å‡å€¼ / æ ‡å‡†å·® ...")
    dataloaders = get_dataloaders(config)

    # 4. è·å–å½’ä¸€åŒ–å‚æ•°
    normalize_obj = None
    for t in dataloaders["train"].dataset.transform.transforms:
        if isinstance(t, Normalize):
            t.compute_stats = True
            normalize_obj = t
            break

    if normalize_obj is None:
        raise RuntimeError("Normalize å®ä¾‹æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ transform åˆ—è¡¨ã€‚")

    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    with torch.no_grad():
        for _ in tqdm(dataloaders["train"], desc="è®¡ç®—å‡å€¼/æ ‡å‡†å·®"):
            pass
    normalize_obj.compute_mean_std()
    normalize_obj.compute_stats = False

    # è·å–å‡å€¼å’Œæ ‡å‡†å·®
    mean = normalize_obj.mean.numpy().squeeze()
    std = normalize_obj.std.numpy().squeeze()
    print(f"âœ… å½’ä¸€åŒ–ç»Ÿè®¡å®Œæˆ: mean={mean}, std={std}")

    # 5. æ„å»ºå¹¶åŠ è½½æ¨¡å‹
    print("ğŸ”§ æ„å»ºå¹¶åŠ è½½æ¨¡å‹...")
    net = get_model(config, device)
    load_from_checkpoint(net, WEIGHTS_PATH, device)
    net.to(device).eval()

    # è·å–æ¨¡å‹å‚æ•°
    patch_size = getattr(net, 'patch_size', 16)
    print(f"â„¹ï¸ ä½¿ç”¨patch_size: {patch_size}")

    # 6. åŠ è½½æ ·æœ¬æ•°æ®
    if PICKLE_FILE and os.path.exists(PICKLE_FILE):
        print(f"ğŸš€ åŠ è½½æ ·æœ¬: {PICKLE_FILE}")
        with open(PICKLE_FILE, 'rb') as f:
            data = pickle.load(f)
        img_data, labels, doys = data['img'], data['labels'], data['doy']

        # æ‰“å°åŸå§‹å½¢çŠ¶ä¿¡æ¯
        print(
            f"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶ - æ—¶é—´æ­¥: {img_data.shape[0]}, é€šé“: {img_data.shape[1]}, ç©ºé—´: {img_data.shape[2]}x{img_data.shape[3]}")

        # åº”ç”¨è‡ªå®šä¹‰å½’ä¸€åŒ–
        normalized_img = custom_normalize(img_data, mean, std)

        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        model_input = prepare_model_input(normalized_img, doys)

        # æ‰“å°è°ƒæ•´åçš„å½¢çŠ¶
        T, C, H, W = model_input.shape
        print(f"ğŸ”„ æ¨¡å‹è¾“å…¥å½¢çŠ¶ - æ—¶é—´æ­¥: {T}, é€šé“: {C}, ç©ºé—´: {H}x{W}")
        print(f"â„¹ï¸ ç©ºé—´ç»´åº¦ {H}x{W} åº”èƒ½è¢« {patch_size} æ•´é™¤: {H % patch_size == 0 and W % patch_size == 0}")

        # è½¬æ¢ä¸ºå¼ é‡å¹¶è°ƒæ•´ç»´åº¦é¡ºåº
        inputs = torch.tensor(model_input, dtype=torch.float32)
        inputs = inputs.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ [1, T, C, H, W]
        inputs = inputs.to(device)
        print(f"ğŸ“¦ è¾“å…¥å¼ é‡å½¢çŠ¶: {inputs.shape}")

        # è®¾ç½®æ¨¡å‹åˆ†ææ¨¡å¼
        net.set_analysis_mode(ANALYSIS_MODE)

        # è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­ - æ•è·æ³¨æ„åŠ›å¾—åˆ†
        print(f"è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­å¹¶æ•è·{ANALYSIS_MODE}æ³¨æ„åŠ›å¾—åˆ†...")
        with torch.no_grad():
            logits, attention_scores_list = modified_forward_with_attention(inputs, net, mode=ANALYSIS_MODE)

        # è®¡ç®—ç©ºé—´å—æ•°é‡
        num_spatial_blocks = (H // patch_size) * (W // patch_size)
        print(f"ç©ºé—´å—æ•°é‡: {num_spatial_blocks}")

        # å¤„ç†é—¨æ§æƒé‡
        if ANALYSIS_MODE == 'spatial' and hasattr(net, 'gate_weights'):
            spatial_gate_weights = net.gate_weights
            print(f"âœ… æ”¶é›†åˆ° {len(spatial_gate_weights)} ä¸ªç©ºé—´é—¨æ§æƒé‡å—")

            # ä¿å­˜CSVæ–‡ä»¶
            save_gate_weights(
                spatial_gate_weights,
                attention_dir,
                "spatial",
                num_positions=num_spatial_blocks
            )

            # ç»˜åˆ¶æŸ±çŠ¶å›¾
            plot_gate_weights(
                spatial_gate_weights,
                attention_dir,
                "spatial",
                num_positions=num_spatial_blocks,
                figsize=(12, 6)
            )
        elif ANALYSIS_MODE == 'temporal' and hasattr(net, 'gate_weights'):
            temporal_gate_weights = net.gate_weights
            print(f"âœ… æ”¶é›†åˆ° {len(temporal_gate_weights)} ä¸ªæ—¶é—´é—¨æ§æƒé‡å—")

            # ä¿å­˜CSVæ–‡ä»¶
            save_gate_weights(
                temporal_gate_weights,
                attention_dir,
                "temporal",
                num_positions=T  # æ—¶é—´æ­¥æ•°é‡
            )
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°é—¨æ§æƒé‡æ•°æ®")

        # è®¡ç®—æ¯å±‚ç©ºé—´å—é‡è¦æ€§
        if ANALYSIS_MODE == 'spatial' and attention_scores_list:
            print("è®¡ç®—æ¯å±‚ç©ºé—´å—é‡è¦æ€§...")

            # ä¸ºæ¯ä¸€å±‚è®¡ç®—å—é‡è¦æ€§
            block_importance_per_layer = compute_spatial_block_importance_per_layer(
                attention_scores_list,
                num_blocks=num_spatial_blocks
            )

            if block_importance_per_layer:
                # åˆ›å»ºDataFrame
                importance_df = pd.DataFrame(
                    block_importance_per_layer,
                    columns=[f"Block_{i}" for i in range(1, num_spatial_blocks + 1)]
                )

                # æ·»åŠ å±‚ç´¢å¼•åˆ—
                importance_df.insert(0, 'Layer', range(1, len(block_importance_per_layer) + 1))

                # ä¿å­˜ä¸ºCSV
                importance_path = os.path.join(SAVE_DIR, "spatial_block_importance_per_layer.csv")
                importance_df.to_csv(importance_path, index=False)
                print(f"âœ… æ¯å±‚ç©ºé—´å—é‡è¦æ€§å·²ä¿å­˜è‡³: {importance_path}")

                # æ‰“å°æ‘˜è¦ä¿¡æ¯
                print(f"å…±è®¡ç®—äº† {len(block_importance_per_layer)} å±‚çš„ç©ºé—´å—é‡è¦æ€§")
                for layer_idx, imp_vec in enumerate(block_importance_per_layer):
                    print(f"ç¬¬ {layer_idx + 1} å±‚é‡è¦æ€§å‘é‡: {imp_vec}")
            else:
                print("âš ï¸ æœªè·å–åˆ°ç©ºé—´å—é‡è¦æ€§æ•°æ®")
        else:
            print("âš ï¸ ç©ºé—´æ¨¡å¼æœªæ£€æµ‹åˆ°æ³¨æ„åŠ›å¾—åˆ†")

        # å¯è§†åŒ–æ³¨æ„åŠ›å¾—åˆ†
        print(f"âœ… æ£€æµ‹åˆ° {len(attention_scores_list)} ä¸ªæ³¨æ„åŠ›å—")
        for block_idx, attention_scores in enumerate(attention_scores_list):
            print(f"\nå¤„ç†å— {block_idx + 1}/{len(attention_scores_list)}")

            if ANALYSIS_MODE == 'temporal':
                # ç»˜åˆ¶æ—¶é—´æ³¨æ„åŠ›çƒ­åŠ›å›¾å’ŒäºŒéƒ¨å›¾
                plot_temporal_attention(attention_scores, attention_dir, block_idx)

                # ç»˜åˆ¶éšæ—¶é—´å˜åŒ–çš„æ³¨æ„åŠ›
                plot_attention_over_time(attention_scores, attention_dir, block_idx)
            else:
                # ç»˜åˆ¶ç©ºé—´æ³¨æ„åŠ›çƒ­åŠ›å›¾
                plot_spatial_attention(attention_scores, attention_dir, block_idx)
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æ ·æœ¬æ–‡ä»¶ {PICKLE_FILE}ï¼Œè¯·æ£€æŸ¥è·¯å¾„")

    print("\nâœ… æ‰€æœ‰æ³¨æ„åŠ›åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨:", SAVE_DIR)
    print("=" * 50)


if __name__ == "__main__":
    main()