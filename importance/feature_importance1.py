#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è®¡ç®— TSViT æ¨¡å‹åœ¨æ—¶åºé¥æ„Ÿæ•°æ®ä¸Šçš„ç‰¹å¾é‡è¦æ€§ï¼ˆæ³¢æ®µ Ã— æ—¶é—´ï¼‰ã€‚
ä¿®å¤äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¹¶ä¼˜åŒ–äº†å¯è§†åŒ–æ•ˆæœã€‚
"""

import os
import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
import pickle
import sys

# --- è·¯å¾„ä¸åŒ… ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from data import get_dataloaders
from data.PASTIS24.data_transforms import Normalize
from models import get_model
from utils.config_files_utils import read_yaml
from utils.torch_utils import get_device, load_from_checkpoint

# å®šä¹‰æ³¢æ®µåç§°
BAND_NAMES = [
    'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B11', 'B12', 'B8A',
    'EVI', 'GCVI', 'GNDVI', 'NDVI', 'NDWI', 'NREDI1', 'NREDI2', 'NREDI3',
    'OSAVI', 'RVI'
]


# --- åŠ è½½å•ä¸ªæ ·æœ¬æ•°æ® ---
def load_single_sample(pickle_file_path):
    """ä» pickle æ–‡ä»¶ä¸­åŠ è½½æ•°æ®"""
    with open(pickle_file_path, 'rb') as f:
        data = pickle.load(f)

    print(f"åŠ è½½æ•°æ®é”®: {list(data.keys())}")
    print(f"å›¾åƒå½¢çŠ¶: {data['img'].shape}")
    print(f"æ ‡ç­¾å½¢çŠ¶: {data['labels'].shape}")
    print(f"æ—¥æœŸå½¢çŠ¶: {data['doy'].shape}")

    return data['img'], data['labels'], data['doy']


# --- è‡ªå®šä¹‰å½’ä¸€åŒ–å¤„ç† ---
def custom_normalize(data, mean, std):
    """æ‰‹åŠ¨åº”ç”¨å½’ä¸€åŒ–å¤„ç†ï¼Œæ”¯æŒä»»æ„ç»´åº¦çš„æ•°æ®"""
    # ç¡®ä¿å‡å€¼å’Œæ ‡å‡†å·®çš„å½¢çŠ¶ä¸æ•°æ®é€šé“ç»´åº¦åŒ¹é…
    mean = mean.squeeze().astype(np.float32)  # ç¡®ä¿ä¸ºfloat32
    std = std.squeeze().astype(np.float32)  # ç¡®ä¿ä¸ºfloat32

    # æ‰©å±•å‡å€¼å’Œæ ‡å‡†å·®çš„ç»´åº¦ä»¥åŒ¹é…æ•°æ®å½¢çŠ¶
    if data.ndim == 4:  # (T, C, H, W)
        mean = mean.reshape(1, -1, 1, 1)
        std = std.reshape(1, -1, 1, 1)
    elif data.ndim == 3:  # (C, H, W)
        mean = mean.reshape(-1, 1, 1)
        std = std.reshape(-1, 1, 1)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç»´åº¦: {data.ndim}")

    # åº”ç”¨å½’ä¸€åŒ–
    normalized = (data - mean) / std
    return normalized.astype(np.float32)  # ç¡®ä¿ä¸ºfloat32


# --- å‡†å¤‡æ¨¡å‹è¾“å…¥ ---
def prepare_model_input(normalized_img, doys):
    """
    å‡†å¤‡ç¬¦åˆæ¨¡å‹è¾“å…¥çš„å¼ é‡
    æ ¹æ®TSViTæ¨¡å‹è¦æ±‚ï¼Œæ·»åŠ æ—¶é—´ç‰¹å¾ä½œä¸ºé¢å¤–é€šé“
    """
    # 1. å‡†å¤‡æ—¶é—´ç‰¹å¾ (ä½œä¸ºé¢å¤–çš„é€šé“)
    # å½’ä¸€åŒ–DOYåˆ°[0,1]èŒƒå›´
    doy_normalized = doys / 365.0

    # æ‰©å±•DOYä¸ºé€šé“ [T, 1, H, W]
    doy_channel = doy_normalized[:, np.newaxis, np.newaxis, np.newaxis]
    doy_channel = np.broadcast_to(doy_channel,
                                  (doy_normalized.shape[0], 1,
                                   normalized_img.shape[2], normalized_img.shape[3]))

    # 2. å°†æ—¶é—´ç‰¹å¾ä½œä¸ºé¢å¤–é€šé“æ·»åŠ 
    model_input = np.concatenate([normalized_img, doy_channel], axis=1)

    print(f"æ¨¡å‹è¾“å…¥å½¢çŠ¶: {model_input.shape} (T, C, H, W)")
    return model_input.astype(np.float32)  # ç¡®ä¿ä¸ºfloat32


# --- å¯è§†åŒ–åŸå§‹è¾“å…¥å€¼ ---
def plot_original_inputs(inputs, band_names, save_path):
    """ç»˜åˆ¶åŸå§‹è¾“å…¥å€¼å¹¶ä¿å­˜"""
    plt.figure(figsize=(14, 8))

    # ç»˜åˆ¶æ‰€æœ‰æ³¢æ®µçš„åŸå§‹è¾“å…¥å€¼
    for i in range(min(len(band_names), inputs.shape[1])):
        plt.plot(inputs[:, i], label=band_names[i], linewidth=2)

    plt.title('åŸå§‹è¾“å…¥å€¼', fontsize=16)
    plt.xlabel('æ—¶é—´æ­¥', fontsize=14)
    plt.ylabel('å½’ä¸€åŒ–å€¼', fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.7)

    # æ·»åŠ å›¾ä¾‹
    plt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), fontsize=10)

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    plt.subplots_adjust(right=0.75)

    # ä¿å­˜å›¾åƒ
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"åŸå§‹è¾“å…¥å€¼å›¾å·²ä¿å­˜è‡³: {save_path}")
    plt.close()


# --- å¯è§†åŒ–æ¢¯åº¦é‡è¦æ€§ ---
def plot_gradients(grads, band_names, save_path):
    """ç»˜åˆ¶æ¢¯åº¦é‡è¦æ€§å¹¶ä¿å­˜"""
    plt.figure(figsize=(8, 2))

    # ç»˜åˆ¶æ‰€æœ‰æ³¢æ®µçš„æ¢¯åº¦é‡è¦æ€§
    for i in range(min(len(band_names), grads.shape[1])):
        plt.plot(grads[:, i], label=band_names[i], linewidth=1)

    # è®¾ç½®æ¨ªåæ ‡é—´éš”ä¸º2
    num_timesteps = grads.shape[0]
    plt.xticks(np.arange(0, num_timesteps, 2))

    plt.title('è¾“å…¥æ¢¯åº¦é‡è¦æ€§', fontsize=16)
    plt.xlabel('æ—¶é—´æ­¥', fontsize=6)
    plt.ylabel('æ¢¯åº¦å€¼', fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.7)

    # æ·»åŠ å›¾ä¾‹
    plt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), fontsize=10)

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    plt.subplots_adjust(right=0.75)

    # ä¿å­˜å›¾åƒ
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"æ¢¯åº¦é‡è¦æ€§å›¾å·²ä¿å­˜è‡³: {save_path}")
    plt.close()


# --- æ—¶é—´ç‰¹å¾å¤„ç† ---
def process_time_features(xt, device):
    """å¤„ç†æ—¶é—´ç‰¹å¾ï¼Œé¿å…ç´¢å¼•é”™è¯¯"""
    # ä¿®æ­£ï¼šç›´æ¥ä¹˜ä»¥365ï¼ˆä¸è¦ç”¨365.0001ï¼‰
    xt = (xt * 365).to(torch.int64)
    xt = torch.clamp(xt, 0, 365)

    # æ£€æŸ¥æœ€å¤§å€¼æ˜¯å¦è¶…è¿‡365
    max_val = xt.max().item()
    if max_val >= 366:
        print(f"âš ï¸ è­¦å‘Š: æœ€å¤§æ—¶é—´ç‰¹å¾å€¼ {max_val} è¶…è¿‡365ï¼Œå°†è¢«è£å‰ª")
        xt = torch.clamp(xt, 0, 365)

    # æ‰§è¡Œone-hotç¼–ç 
    xt = F.one_hot(xt, num_classes=366).to(torch.float32)
    return xt


# --- åˆ›å»ºå®Œæ•´ç›®æ ‡å›¾ ---
def create_full_target_map(logits, labels, device):
    """
    åˆ›å»ºå®Œæ•´çš„ç›®æ ‡çƒ­åŠ›å›¾ï¼ˆä½¿ç”¨çœŸå®æ ‡ç­¾ï¼‰
    logits: [1, num_classes, H, W]
    labels: [H, W] (numpy array)
    """
    target = torch.zeros_like(logits).to(device)
    _, num_classes, H, W = logits.shape
    # ç¡®ä¿æ ‡ç­¾å½¢çŠ¶åŒ¹é…
    if labels.shape[0] != H or labels.shape[1] != W:
        labels = labels[:H, :W]  # è£å‰ªåˆ°ç›¸åŒç©ºé—´å°ºå¯¸
    for y in range(H):
        for x in range(W):
            class_idx = labels[y, x]
            if class_idx < num_classes:  # ç¡®ä¿ä¸è¶Šç•Œ
                target[0, class_idx, y, x] = 1.0
    return target


# --- ä¿®æ”¹åçš„å‰å‘ä¼ æ’­ ---
def modified_forward(inputs, net):
    """ä¿®æ”¹åçš„æ¨¡å‹å‰å‘ä¼ æ’­å‡½æ•°ï¼Œä¿®å¤æ•°æ®ç±»å‹å’Œå½¢çŠ¶é—®é¢˜"""
    # æå–è¾“å…¥å½¢çŠ¶
    B, T, C, H, W = inputs.shape

    # ç¡®ä¿è¾“å…¥æ˜¯float32ç±»å‹
    inputs = inputs.float()

    # æå–æ—¶é—´ç‰¹å¾ (æœ€åä¸€ä¸ªé€šé“)
    xt = inputs[:, :, -1, 0, 0]
    xt = process_time_features(xt, inputs.device)
    xt = xt.reshape(-1, 366)

    # åº”ç”¨æ—¶é—´ä½ç½®åµŒå…¥
    temporal_pos_embedding = net.to_temporal_embedding_input(xt).reshape(B, T, net.dim)

    # å‡†å¤‡patchåµŒå…¥
    x = inputs[:, :, :-1]  # ç§»é™¤æ—¶é—´ç‰¹å¾é€šé“ï¼Œä¿ç•™20ä¸ªæ³¢æ®µ [B, T, 20, H, W]

    # ç¡®ä¿ç©ºé—´ç»´åº¦èƒ½è¢«patch_sizeæ•´é™¤
    assert H % net.patch_size == 0, f"é«˜åº¦ {H} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"
    assert W % net.patch_size == 0, f"å®½åº¦ {W} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"

    # è®¡ç®—patchæ•°é‡
    num_patches_h = H // net.patch_size
    num_patches_w = W // net.patch_size
    num_patches = num_patches_h * num_patches_w

    # æ‰‹åŠ¨å®ç°Rearrangeæ“ä½œ
    x = x.view(B, T, 20, num_patches_h, net.patch_size, num_patches_w, net.patch_size)
    x = x.permute(0, 3, 5, 1, 4, 6, 2)  # [B, num_patches_h, num_patches_w, T, patch_size, patch_size, C]
    x = x.reshape(B * num_patches_h * num_patches_w, T, net.patch_size * net.patch_size * 20)

    # åº”ç”¨çº¿æ€§å˜æ¢
    x = net.to_patch_embedding[1](x)  # åªåº”ç”¨çº¿æ€§å±‚ï¼Œè·³è¿‡Rearrange

    # æ·»åŠ æ—¶é—´ä½ç½®åµŒå…¥
    x = x.reshape(B, num_patches, T, net.dim)
    x += temporal_pos_embedding.unsqueeze(1)
    x = x.reshape(B * num_patches, T, net.dim)

    # æ·»åŠ æ—¶é—´token
    cls_temporal_tokens = net.temporal_token.repeat(B * num_patches, 1, 1)
    x = torch.cat((cls_temporal_tokens, x), dim=1)

    # æ—¶é—´å˜æ¢å™¨
    x = net.temporal_transformer(x)
    x = x[:, :net.num_classes]

    # ç©ºé—´å˜æ¢å™¨
    x = x.reshape(B, num_patches, net.num_classes, net.dim).permute(0, 2, 1, 3).reshape(B * net.num_classes,
                                                                                        num_patches, net.dim)

    # ç¡®ä¿ç©ºé—´ä½ç½®åµŒå…¥å¤§å°åŒ¹é…
    space_pos_embedding = net.space_pos_embedding[:, :num_patches] if net.space_pos_embedding.shape[
                                                                          1] > num_patches else net.space_pos_embedding
    x += space_pos_embedding

    # åº”ç”¨dropout
    if hasattr(net, 'dropout'):
        x = net.dropout(x)

    # ç©ºé—´å˜æ¢å™¨
    x = net.space_transformer(x)

    # MLPå¤´éƒ¨
    x = net.mlp_head(x.reshape(-1, net.dim))

    # é‡å¡‘è¾“å‡º
    x = x.reshape(B, net.num_classes, num_patches, net.patch_size ** 2)
    x = x.permute(0, 2, 3, 1)  # [B, num_patches, patch_size**2, num_classes]

    # é‡å¡‘ä¸ºæœ€ç»ˆè¾“å‡ºå½¢çŠ¶
    # é¦–å…ˆé‡å¡‘ä¸º [B, num_patches_h, num_patches_w, patch_size, patch_size, num_classes]
    x = x.reshape(B, num_patches_h, num_patches_w, net.patch_size, net.patch_size, net.num_classes)

    # ç„¶åç»„åˆä¸ºå®Œæ•´å›¾åƒ
    # ç»„åˆé«˜åº¦å—
    x = x.permute(0, 1, 3, 2, 4, 5)  # [B, num_patches_h, patch_size, num_patches_w, patch_size, num_classes]
    x = x.reshape(B, num_patches_h * net.patch_size, num_patches_w * net.patch_size, net.num_classes)

    # è°ƒæ•´ç»´åº¦é¡ºåº
    x = x.permute(0, 3, 1, 2)  # [B, num_classes, H, W]
    return x


# ---------- ä¸»å‡½æ•° ----------
def main(cfg_path, weights_path, device_ids, save_dir, pickle_file_path):
    # 0. è®¾å¤‡
    device = get_device(device_ids, allow_cpu=False)

    # 1. åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)

    # 2. è¯»å–é…ç½®
    config = read_yaml(cfg_path)
    config["local_device_ids"] = device_ids

    # 3. åˆ›å»ºä¸´æ—¶dataloaderä»¥è·å–å½’ä¸€åŒ–å‚æ•°
    print("ğŸ“Š ç»Ÿè®¡è®­ç»ƒé›†å‡å€¼ / æ ‡å‡†å·® ...")
    dataloaders = get_dataloaders(config)

    # 4. è·å–å½’ä¸€åŒ–å‚æ•°
    normalize_obj = None
    for t in dataloaders["train"].dataset.transform.transforms:
        if isinstance(t, Normalize):
            t.compute_stats = True
            normalize_obj = t
            break

    if normalize_obj is None:
        raise RuntimeError("Normalize å®ä¾‹æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ transform åˆ—è¡¨ã€‚")

    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    with torch.no_grad():
        for _ in tqdm(dataloaders["train"], desc="è®¡ç®—å‡å€¼/æ ‡å‡†å·®"):
            pass
    normalize_obj.compute_mean_std()
    normalize_obj.compute_stats = False

    # è·å–å‡å€¼å’Œæ ‡å‡†å·®
    mean = normalize_obj.mean.numpy().squeeze()
    std = normalize_obj.std.numpy().squeeze()
    print(f"âœ… å½’ä¸€åŒ–ç»Ÿè®¡å®Œæˆ: mean={mean}, std={std}")

    # 5. æ„å»ºå¹¶åŠ è½½æ¨¡å‹
    net = get_model(config, device)
    load_from_checkpoint(net, weights_path, device)
    net.to(device).eval()
    if len(device_ids) > 1:
        net = torch.nn.DataParallel(net, device_ids=device_ids)

    # 6. åŠ è½½å¹¶åˆ†æå•ä¸ªæ ·æœ¬
    print(f"ğŸš€ åŠ è½½æ ·æœ¬: {pickle_file_path}")
    img_data, labels, doys = load_single_sample(pickle_file_path)

    # 7. åº”ç”¨è‡ªå®šä¹‰å½’ä¸€åŒ–
    normalized_img = custom_normalize(img_data, mean, std)
    print(f"å½’ä¸€åŒ–åå›¾åƒå½¢çŠ¶: {normalized_img.shape}")

    # 8. å‡†å¤‡æ¨¡å‹è¾“å…¥
    model_input = prepare_model_input(normalized_img, doys)
    inputs = torch.tensor(model_input, dtype=torch.float32).unsqueeze(0).to(device)  # [1, T, C, H, W]
    inputs.requires_grad = True

    # 9. å‰å‘ä¼ æ’­
    print("è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­...")

    # ä½¿ç”¨ä¿®æ”¹åçš„å‰å‘ä¼ æ’­
    logits = modified_forward(inputs, net.module if hasattr(net, 'module') else net)
    print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {logits.shape}")

    # 10. è®¡ç®—ç›®æ ‡ç±»åˆ«å¾—åˆ†å¹¶åå‘ä¼ æ’­
    # åˆ›å»ºå®Œæ•´çš„ç›®æ ‡å›¾ï¼ˆä½¿ç”¨çœŸå®æ ‡ç­¾ï¼‰
    target = create_full_target_map(logits, labels, device)

    # å…³é”®ä¿®æ”¹1ï¼šä½¿ç”¨softmaxæ¦‚ç‡è®¡ç®—æŸå¤±
    probs = F.softmax(logits, dim=1)

    # å…³é”®ä¿®æ”¹2ï¼šä½¿ç”¨äº¤å‰ç†µæŸå¤±ä»£æ›¿ç‚¹ä¹˜æŸå¤±
    loss = - (target * torch.log(probs + 1e-10)).sum()

    # å…³é”®ä¿®æ”¹3ï¼šæ¢¯åº¦æ”¾å¤§ï¼ˆè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼‰
    scaled_loss = loss * 1000

    # åå‘ä¼ æ’­
    net.zero_grad()
    scaled_loss.backward()

    # è·å–æ¢¯åº¦å¹¶è¿˜åŸï¼ˆé™¤ä»¥æ”¾å¤§å€æ•°ï¼‰
    grads = inputs.grad.detach().cpu().numpy()[0] / 1000  # [T, C, H, W]
    print(f"æ¢¯åº¦å½¢çŠ¶: {grads.shape}")

    # æ‰“å°æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯
    print(f"æ¢¯åº¦èŒƒå›´: {grads.min():.6f} ~ {grads.max():.6f}")
    print(f"æ¢¯åº¦å‡å€¼: {grads.mean():.6f}, ç»å¯¹å€¼å‡å€¼: {np.abs(grads).mean():.6f}")

    # 11. è®¡ç®—ç‰¹å¾é‡è¦æ€§ (æŒ‰æ—¶é—´å’Œæ³¢æ®µå¹³å‡)
    # ç©ºé—´å¹³å‡
    grads_spatial_avg = grads.mean(axis=(2, 3))  # [T, C]

    # åªå–å‰20ä¸ªæ³¢æ®µï¼ˆå¿½ç•¥æ—¶é—´ç‰¹å¾é€šé“ï¼‰
    grads_spatial_avg = grads_spatial_avg[:, :20]

    # ä¿å­˜ç‰¹å¾é‡è¦æ€§æ•°æ®
    feature_importance_path = os.path.join(save_dir, "feature_importance.csv")
    df = pd.DataFrame(grads_spatial_avg, columns=BAND_NAMES)
    df['TimeStep'] = range(1, len(df) + 1)
    df.set_index('TimeStep', inplace=True)
    df.to_csv(feature_importance_path)
    print(f"âœ… ç‰¹å¾é‡è¦æ€§æ•°æ®å·²ä¿å­˜è‡³: {feature_importance_path}")

    # 12. å¯è§†åŒ–
    # é€‰æ‹©ä¸­å¿ƒåƒç´ çš„è¾“å…¥å€¼ï¼ˆåªå–å‰20ä¸ªæ³¢æ®µï¼‰
    center_inputs = normalized_img[:, :, labels.shape[0] // 2, labels.shape[1] // 2]  # ä½¿ç”¨æ ‡ç­¾å›¾çš„ä¸­å¿ƒ

    # åˆ†åˆ«ä¿å­˜ä¸¤å¼ å›¾è¡¨
    input_plot_path = os.path.join(save_dir, "original_inputs_plot.png")
    plot_original_inputs(center_inputs, BAND_NAMES, input_plot_path)

    gradient_plot_path = os.path.join(save_dir, "gradients_plot.png")
    plot_gradients(grads_spatial_avg, BAND_NAMES, gradient_plot_path)

    # 13. ä¿å­˜åŸå§‹è¾“å…¥å’Œæ¢¯åº¦æ•°æ®
    np.save(os.path.join(save_dir, "original_inputs.npy"), img_data)
    np.save(os.path.join(save_dir, "normalized_inputs.npy"), normalized_img)
    np.save(os.path.join(save_dir, "gradients.npy"), grads)
    print("âœ… æ‰€æœ‰æ•°æ®æ–‡ä»¶å·²ä¿å­˜")


# ---------- å…¥å£ ----------
if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    cfg_path = r"C:\Users\Think\Desktop\DeepSatModels-main\configs\PASTIS24\TSViT_fold5.yaml"
    weights_path = r"C:\Users\Think\Desktop\æ¨¡å‹\logs\é—¨æ§è‡ªé€‚åº”8684\best.pth"
    pickle_file_path = r"C:\Users\Think\Desktop\bq\bq_new_new\kuochong_30\64\total2\20369_0_0.pickle"
    save_dir = r"C:\Users\Think\Desktop\feature_importance_results"
    device_ids = [0]  # ä½¿ç”¨ GPU 0

    # æ·»åŠ CUDAåˆå§‹åŒ–æ£€æŸ¥
    torch.cuda.init()
    if not torch.cuda.is_initialized():
        print("âš ï¸ CUDAæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œå°è¯•ä½¿ç”¨CPU")
        device_ids = []  # å›é€€åˆ°CPU

    main(
        cfg_path=cfg_path,
        weights_path=weights_path,
        device_ids=device_ids,
        save_dir=save_dir,
        pickle_file_path=pickle_file_path
    )