#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é—¨æ§æƒé‡å¯è§†åŒ–è„šæœ¬ - æ”¯æŒæ—¶é—´å’Œç©ºé—´æ¨¡å¼
"""

import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from tqdm import tqdm
import sys
import torch.nn.functional as F

# --- æ·»åŠ é¡¹ç›®è·¯å¾„ ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# --- å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ---
from data import get_dataloaders
from data.PASTIS24.data_transforms import Normalize
from models import get_model
from utils.config_files_utils import read_yaml
from utils.torch_utils import get_device, load_from_checkpoint

# ===========================================
# ç›´æ¥è®¾ç½®è·¯å¾„å’Œå‚æ•°
# ===========================================

CFG_PATH = r"C:\Users\Think\Desktop\DeepSatModels-main\configs\PASTIS24\TSViT_fold5.yaml"
WEIGHTS_PATH = r"C:\Users\Think\Desktop\æ¨¡å‹\logs\é—¨æ§è‡ªé€‚åº”8684\best.pth"
SAVE_DIR = r"C:\Users\Think\Desktop\gate"
PICKLE_FILE = r"C:\Users\Think\Desktop\bq\bq_new_new\kuochong_30\64\total2\20369_1_0.pickle"
NUM_SAMPLES = 5
DEVICE_IDS = [0]
ANALYSIS_MODE = 'spatial'  # å¯é€‰ 'temporal' æˆ– 'spatial'


# ===========================================
# ä¿®å¤åçš„æ•°æ®å¤„ç†å‡½æ•°
# ===========================================

def custom_normalize(data, mean, std):
    """æ‰‹åŠ¨åº”ç”¨å½’ä¸€åŒ–å¤„ç†ï¼Œä¿æŒæ—¶é—´æ­¥é•¿ä¸å˜"""
    mean = mean.squeeze().astype(np.float32)
    std = std.squeeze().astype(np.float32)

    if data.ndim == 4:  # (T, C, H, W)
        mean = mean.reshape(1, -1, 1, 1)
        std = std.reshape(1, -1, 1, 1)
    elif data.ndim == 3:  # (C, H, W)
        mean = mean.reshape(-1, 1, 1)
        std = std.reshape(-1, 1, 1)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç»´åº¦: {data.ndim}")

    normalized = (data - mean) / std
    return normalized.astype(np.float32)


def prepare_model_input(normalized_img, doys):
    """
    å‡†å¤‡ç¬¦åˆæ¨¡å‹è¾“å…¥çš„å¼ é‡
    å…³é”®ä¿®æ”¹ï¼šä¿æŒåŸå§‹å½¢çŠ¶ä¸å˜ï¼Œå¹¶æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    """
    doy_normalized = doys / 365.0
    doy_channel = doy_normalized[:, np.newaxis, np.newaxis, np.newaxis]
    doy_channel = np.broadcast_to(
        doy_channel,
        (doy_normalized.shape[0], 1, normalized_img.shape[2], normalized_img.shape[3])
    )

    model_input = np.concatenate([normalized_img, doy_channel], axis=1)
    return model_input.astype(np.float32)


# --- æ—¶é—´ç‰¹å¾å¤„ç† ---
def process_time_features(xt, device):
    """å¤„ç†æ—¶é—´ç‰¹å¾ï¼Œé¿å…ç´¢å¼•é”™è¯¯"""
    # ç¡®ä¿æ—¶é—´ç‰¹å¾åœ¨åˆç†èŒƒå›´å†…
    xt = torch.clamp(xt * 365.0001, 0, 365)
    xt = xt.to(torch.int64)

    # æ£€æŸ¥æœ€å¤§å€¼æ˜¯å¦è¶…è¿‡365
    max_val = xt.max().item()
    if max_val >= 366:
        print(f"âš ï¸ è­¦å‘Š: æœ€å¤§æ—¶é—´ç‰¹å¾å€¼ {max_val} è¶…è¿‡365ï¼Œå°†è¢«è£å‰ª")
        xt = torch.clamp(xt, 0, 365)

    # æ‰§è¡Œone-hotç¼–ç 
    xt = F.one_hot(xt, num_classes=366).to(torch.float32)
    return xt


# --- ä¿®æ”¹åçš„å‰å‘ä¼ æ’­ ---
def modified_forward(inputs, net):
    """ä¿®æ”¹åçš„æ¨¡å‹å‰å‘ä¼ æ’­å‡½æ•°ï¼Œä¿®å¤æ•°æ®ç±»å‹å’Œå½¢çŠ¶é—®é¢˜"""
    # æå–è¾“å…¥å½¢çŠ¶
    B, T, C, H, W = inputs.shape

    # ç¡®ä¿è¾“å…¥æ˜¯float32ç±»å‹
    inputs = inputs.float()

    # æå–æ—¶é—´ç‰¹å¾ (æœ€åä¸€ä¸ªé€šé“)
    xt = inputs[:, :, -1, 0, 0]
    xt = process_time_features(xt, inputs.device)
    xt = xt.reshape(-1, 366)

    # åº”ç”¨æ—¶é—´ä½ç½®åµŒå…¥
    temporal_pos_embedding = net.to_temporal_embedding_input(xt).reshape(B, T, net.dim)

    # å‡†å¤‡patchåµŒå…¥ - æ‰‹åŠ¨å®ç°é‡æ’
    x = inputs[:, :, :-1]  # ç§»é™¤æ—¶é—´ç‰¹å¾é€šé“ï¼Œä¿ç•™20ä¸ªæ³¢æ®µ [B, T, 20, H, W]

    # ç¡®ä¿ç©ºé—´ç»´åº¦èƒ½è¢«patch_sizeæ•´é™¤
    assert H % net.patch_size == 0, f"é«˜åº¦ {H} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"
    assert W % net.patch_size == 0, f"å®½åº¦ {W} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"

    # è®¡ç®—patchæ•°é‡
    num_patches_h = H // net.patch_size
    num_patches_w = W // net.patch_size
    num_patches = num_patches_h * num_patches_w

    # æ‰‹åŠ¨å®ç°é‡æ’æ“ä½œ
    # åŸå§‹å½¢çŠ¶: [B, T, 20, H, W]
    # ç›®æ ‡å½¢çŠ¶: [B * num_patches, T, patch_size * patch_size * 20]
    # ä½¿ç”¨unfoldæ“ä½œæå–patch
    x = x.unfold(3, net.patch_size, net.patch_size)  # åœ¨é«˜åº¦ç»´åº¦ä¸Šå±•å¼€
    x = x.unfold(4, net.patch_size, net.patch_size)  # åœ¨å®½åº¦ç»´åº¦ä¸Šå±•å¼€

    # ç°åœ¨å½¢çŠ¶ä¸º: [B, T, 20, num_patches_h, num_patches_w, patch_size, patch_size]
    # è°ƒæ•´ç»´åº¦é¡ºåº
    x = x.permute(0, 3, 4, 1, 2, 5, 6)  # [B, num_patches_h, num_patches_w, T, 20, patch_size, patch_size]

    # åˆå¹¶patchå’Œé€šé“ç»´åº¦
    x = x.reshape(B * num_patches_h * num_patches_w, T, 20 * net.patch_size * net.patch_size)

    # åº”ç”¨çº¿æ€§å˜æ¢
    x = net.to_patch_embedding[1](x)  # [B*num_patches, T, dim]

    # æ·»åŠ æ—¶é—´ä½ç½®åµŒå…¥
    x = x.reshape(B, num_patches, T, net.dim)  # [B, num_patches, T, dim]
    x += temporal_pos_embedding.unsqueeze(1)  # [B, num_patches, T, dim]
    x = x.reshape(B * num_patches, T, net.dim)  # [B*num_patches, T, dim]

    # æ·»åŠ æ—¶é—´token
    cls_temporal_tokens = net.temporal_token.repeat(B * num_patches, 1, 1)
    x = torch.cat((cls_temporal_tokens, x), dim=1)  # [B*num_patches, T+num_classes, dim]

    # âœ… å¼€å¯æ”¶é›†é—¨æ§æƒé‡
    net.temporal_transformer.collect_gate_weights = True

    # æ—¶é—´å˜æ¢å™¨ - è¿™é‡Œè®°å½•é—¨æ§æƒé‡
    x = net.temporal_transformer(x)
    x = x[:, :net.num_classes]  # [B*num_patches, num_classes, dim]

    # ç©ºé—´å˜æ¢å™¨
    x = x.reshape(B, num_patches, net.num_classes, net.dim)  # [B, num_patches, num_classes, dim]
    x = x.permute(0, 2, 1, 3)  # [B, num_classes, num_patches, dim]
    x = x.reshape(B * net.num_classes, num_patches, net.dim)  # [B*num_classes, num_patches, dim]

    # ç¡®ä¿ç©ºé—´ä½ç½®åµŒå…¥å¤§å°åŒ¹é…
    space_pos_embedding = net.space_pos_embedding[:, :num_patches] if net.space_pos_embedding.shape[
                                                                          1] > num_patches else net.space_pos_embedding
    x += space_pos_embedding

    # åº”ç”¨dropout
    if hasattr(net, 'dropout'):
        x = net.dropout(x)

    if hasattr(net, 'collect_gate_weights'):
        net.collect_gate_weights = True
    if hasattr(net.space_transformer, 'collect_gate_weights'):
        net.space_transformer.collect_gate_weights = True

    # ç©ºé—´å˜æ¢å™¨
    x = net.space_transformer(x)  # [B*num_classes, num_patches, dim]

    # MLPå¤´éƒ¨
    x = net.mlp_head(x.reshape(-1, net.dim))  # [B*num_classes*num_patches, patch_size**2]

    # é‡å¡‘è¾“å‡º
    x = x.reshape(B, net.num_classes, num_patches, net.patch_size ** 2)  # [B, num_classes, num_patches, patch_size**2]
    x = x.permute(0, 2, 3, 1)  # [B, num_patches, patch_size**2, num_classes]

    # é‡å¡‘ä¸ºæœ€ç»ˆè¾“å‡ºå½¢çŠ¶
    # é¦–å…ˆé‡å¡‘ä¸º [B, num_patches_h, num_patches_w, patch_size, patch_size, num_classes]
    x = x.reshape(B, num_patches_h, num_patches_w, net.patch_size, net.patch_size, net.num_classes)

    # ç„¶åç»„åˆä¸ºå®Œæ•´å›¾åƒ
    # ç»„åˆé«˜åº¦å—
    x = x.permute(0, 1, 3, 2, 4, 5)  # [B, num_patches_h, patch_size, num_patches_w, patch_size, num_classes]
    x = x.reshape(B, num_patches_h * net.patch_size, num_patches_w * net.patch_size, net.num_classes)

    # è°ƒæ•´ç»´åº¦é¡ºåº
    x = x.permute(0, 3, 1, 2)  # [B, num_classes, H, W]
    return x


# --- å¯è§†åŒ–é—¨æ§æƒé‡ ---
def plot_gate_weights(gate_weights, save_dir, block_idx, mode='spatial'):
    import numpy as np
    os.makedirs(save_dir, exist_ok=True)
    mode_dir = os.path.join(save_dir, mode)
    os.makedirs(mode_dir, exist_ok=True)

    attn_values = gate_weights['attn_weights']  # [S, D]
    mamba_values = gate_weights['mamba_weights']  # [S, D]

    # âœ… ä¿å­˜CSVï¼ˆæ¯ä¸ªpatchä¸€è¡Œï¼Œæ¯åˆ—æ˜¯é€šé“ï¼‰
    attn_df = pd.DataFrame(attn_values)
    mamba_df = pd.DataFrame(mamba_values)

    attn_csv = os.path.join(mode_dir, f'attn_gate_weights_block_{block_idx}.csv')
    mamba_csv = os.path.join(mode_dir, f'mamba_gate_weights_block_{block_idx}.csv')
    attn_df.to_csv(attn_csv, index=False)
    mamba_df.to_csv(mamba_csv, index=False)
    print(f"âœ… CSVå·²ä¿å­˜: {attn_csv} / {mamba_csv}")

    # âœ… çƒ­åŠ›å›¾ç»˜åˆ¶
    for name, values in zip(["Attention", "Mamba"], [attn_values, mamba_values]):
        plt.figure(figsize=(12, 6))
        sns.heatmap(values, cmap="viridis", cbar=True)
        plt.title(f'{name} Gate Weights Heatmap - Block {block_idx}', fontsize=14)
        plt.xlabel('Channel Dimension (D)', fontsize=12)
        plt.ylabel('Patch Index (S)', fontsize=12)
        save_path = os.path.join(mode_dir, f'{name.lower()}_gate_weights_block_{block_idx}_heatmap.png')
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        plt.close()
        print(f"âœ… çƒ­åŠ›å›¾å·²ä¿å­˜: {save_path}")


# --- å¤„ç†æƒé‡æ•°æ® ---
def process_weights(weights_dict, mode='temporal'):
    attn_weights = weights_dict['attn']  # [B, L, D]
    mamba_weights = weights_dict['mamba']

    # è½¬æ¢ä¸ºNumPy
    if isinstance(attn_weights, torch.Tensor):
        attn_weights = attn_weights.cpu().numpy()
    if isinstance(mamba_weights, torch.Tensor):
        mamba_weights = mamba_weights.cpu().numpy()

    # +++ æ–°å¢ï¼šæ—¶é—´æ¨¡å¼ä¸‹ç§»é™¤ç±»åˆ«token +++
    if mode == 'temporal' and attn_weights.shape[1] > 4:
        # å»æ‰å‰4ä¸ªç±»åˆ«token
        attn_weights = attn_weights[:, 4:, :]
        mamba_weights = mamba_weights[:, 4:, :]
        print(f"âœ… å·²ç§»é™¤å‰4ä¸ªç±»åˆ«tokenï¼Œå‰©ä½™æ—¶é—´æ­¥: {attn_weights.shape[1]}")

    # æ ¹æ®æ¨¡å¼å¤„ç†æƒé‡
    if mode == 'temporal':
        # æ—¶é—´æ¨¡å¼: åœ¨æ‰¹æ¬¡å’Œé€šé“ç»´åº¦å–å¹³å‡ [B, T, D] -> [T]
        attn_avg = np.mean(attn_weights, axis=(0, 2))
        mamba_avg = np.mean(mamba_weights, axis=(0, 2))
    else:
        # ç©ºé—´æ¨¡å¼: åœ¨æ‰¹æ¬¡å’Œé€šé“ç»´åº¦å–å¹³å‡ [B, S, D] -> [S]
        # attn_avg = np.mean(attn_weights, axis=(0, 2))
        # mamba_avg = np.mean(mamba_weights, axis=(0, 2))
        attn_avg = np.mean(attn_weights, axis=0)  # â†’ shape: [S, D]
        mamba_avg = np.mean(mamba_weights, axis=0)

    return {
        'attn_weights': attn_avg,
        'mamba_weights': mamba_avg
    }

# --- ä¸»å‡½æ•° ---
def main():
    print("=" * 50)
    print(f"æ¨¡å‹é…ç½®æ–‡ä»¶: {CFG_PATH}")
    print(f"æ¨¡å‹æƒé‡æ–‡ä»¶: {WEIGHTS_PATH}")
    print(f"ç»“æœä¿å­˜ç›®å½•: {SAVE_DIR}")
    print(f"åˆ†ææ¨¡å¼: {ANALYSIS_MODE}")
    print(f"ä½¿ç”¨è®¾å¤‡: {'GPU' if DEVICE_IDS else 'CPU'} {DEVICE_IDS}")
    print("=" * 50)

    # 0. è®¾å¤‡è®¾ç½®
    device = get_device(DEVICE_IDS, allow_cpu=True)

    # 1. åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(SAVE_DIR, exist_ok=True)
    gate_weights_dir = os.path.join(SAVE_DIR, "gate_weights")
    os.makedirs(gate_weights_dir, exist_ok=True)
    print(f"ğŸ“ ç»“æœå°†ä¿å­˜åœ¨: {gate_weights_dir}")

    # 2. è¯»å–é…ç½®
    config = read_yaml(CFG_PATH)
    config["local_device_ids"] = DEVICE_IDS

    # 3. åˆ›å»ºä¸´æ—¶dataloaderä»¥è·å–å½’ä¸€åŒ–å‚æ•°
    print("ğŸ“Š ç»Ÿè®¡è®­ç»ƒé›†å‡å€¼ / æ ‡å‡†å·® ...")
    dataloaders = get_dataloaders(config)

    # 4. è·å–å½’ä¸€åŒ–å‚æ•°
    normalize_obj = None
    for t in dataloaders["train"].dataset.transform.transforms:
        if isinstance(t, Normalize):
            t.compute_stats = True
            normalize_obj = t
            break

    if normalize_obj is None:
        raise RuntimeError("Normalize å®ä¾‹æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ transform åˆ—è¡¨ã€‚")

    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    with torch.no_grad():
        for _ in tqdm(dataloaders["train"], desc="è®¡ç®—å‡å€¼/æ ‡å‡†å·®"):
            pass
    normalize_obj.compute_mean_std()
    normalize_obj.compute_stats = False

    # è·å–å‡å€¼å’Œæ ‡å‡†å·®
    mean = normalize_obj.mean.numpy().squeeze()
    std = normalize_obj.std.numpy().squeeze()
    print(f"âœ… å½’ä¸€åŒ–ç»Ÿè®¡å®Œæˆ: mean={mean}, std={std}")

    # 5. æ„å»ºå¹¶åŠ è½½æ¨¡å‹
    print("ğŸ”§ æ„å»ºå¹¶åŠ è½½æ¨¡å‹...")
    net = get_model(config, device)
    load_from_checkpoint(net, WEIGHTS_PATH, device)
    net.to(device).eval()

    # è®¾ç½®åˆ†ææ¨¡å¼
    if hasattr(net, 'set_analysis_mode'):
        net.set_analysis_mode(ANALYSIS_MODE)
        print(f"âœ… è®¾ç½®åˆ†ææ¨¡å¼: {ANALYSIS_MODE}")

    # è·å–æ¨¡å‹å‚æ•°
    patch_size = getattr(net, 'patch_size', 16)
    print(f"â„¹ï¸ ä½¿ç”¨patch_size: {patch_size}")

    # 6. åŠ è½½æ ·æœ¬æ•°æ®
    if PICKLE_FILE and os.path.exists(PICKLE_FILE):
        # ä»å•ä¸ªpickleæ–‡ä»¶åŠ è½½æ ·æœ¬
        print(f"ğŸš€ åŠ è½½æ ·æœ¬: {PICKLE_FILE}")
        with open(PICKLE_FILE, 'rb') as f:
            data = pickle.load(f)
        img_data, labels, doys = data['img'], data['labels'], data['doy']

        # æ‰“å°åŸå§‹å½¢çŠ¶ä¿¡æ¯
        print(
            f"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶ - æ—¶é—´æ­¥: {img_data.shape[0]}, é€šé“: {img_data.shape[1]}, ç©ºé—´: {img_data.shape[2]}x{img_data.shape[3]}")

        # åº”ç”¨è‡ªå®šä¹‰å½’ä¸€åŒ–
        normalized_img = custom_normalize(img_data, mean, std)

        # å‡†å¤‡æ¨¡å‹è¾“å…¥ï¼ˆä½¿ç”¨ä¿®æ”¹åçš„å‡½æ•°ï¼‰
        model_input = prepare_model_input(normalized_img, doys)

        # æ‰“å°è°ƒæ•´åçš„å½¢çŠ¶
        T, C, H, W = model_input.shape
        print(f"ğŸ”„ æ¨¡å‹è¾“å…¥å½¢çŠ¶ - æ—¶é—´æ­¥: {T}, é€šé“: {C}, ç©ºé—´: {H}x{W}")
        print(f"â„¹ï¸ ç©ºé—´ç»´åº¦ {H}x{W} åº”èƒ½è¢« {patch_size} æ•´é™¤: {H % patch_size == 0 and W % patch_size == 0}")

        # è½¬æ¢ä¸ºå¼ é‡å¹¶è°ƒæ•´ç»´åº¦é¡ºåºä»¥åŒ¹é…æ¨¡å‹æœŸæœ›
        # æ¨¡å‹æœŸæœ›ç»´åº¦é¡ºåº: [batch, time, channels, height, width]
        inputs = torch.tensor(model_input, dtype=torch.float32)  # [T, C, H, W]
        inputs = inputs.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ [1, T, C, H, W]
        inputs = inputs.to(device)
        print(f"ğŸ“¦ è¾“å…¥å¼ é‡å½¢çŠ¶: {inputs.shape}")

        # è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­ - ä½¿ç”¨ä¿®å¤åçš„å‰å‘ä¼ æ’­
        print("è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­...")
        with torch.no_grad():
            logits = modified_forward(inputs, net)

        # æ ¹æ®åˆ†ææ¨¡å¼è·å–é—¨æ§æƒé‡
        if ANALYSIS_MODE == 'temporal':
            # æ—¶é—´æ¨¡å¼
            if hasattr(net.temporal_transformer, 'gate_weights') and net.temporal_transformer.gate_weights:
                gate_weights = net.temporal_transformer.gate_weights
                print(f"âœ… [æ—¶é—´] æ£€æµ‹åˆ° {len(gate_weights)} ä¸ªé—¨æ§æƒé‡å—")

                for block_idx, weights_dict in enumerate(gate_weights):
                    # å¤„ç†æƒé‡æ•°æ®
                    processed_weights = process_weights(weights_dict, mode='temporal')

                    # å¯è§†åŒ–
                    plot_gate_weights(processed_weights, gate_weights_dir, block_idx, mode='temporal')
            else:
                print("âš ï¸ è­¦å‘Š: æ—¶é—´è½¬æ¢å™¨æ²¡æœ‰'gate_weights'å±æ€§æˆ–è¯¥å±æ€§ä¸ºç©º")
        else:
            # ç©ºé—´æ¨¡å¼
            if hasattr(net.space_transformer, 'gate_weights') and net.space_transformer.gate_weights:
                gate_weights = net.space_transformer.gate_weights
                print(f"âœ… [ç©ºé—´] æ£€æµ‹åˆ° {len(gate_weights)} ä¸ªé—¨æ§æƒé‡å—")

                for block_idx, weights_dict in enumerate(gate_weights):
                    # å¤„ç†æƒé‡æ•°æ®
                    processed_weights = process_weights(weights_dict, mode='spatial')

                    # å¯è§†åŒ–
                    plot_gate_weights(processed_weights, gate_weights_dir, block_idx, mode='spatial')
            else:
                print("âš ï¸ è­¦å‘Š: ç©ºé—´è½¬æ¢å™¨æ²¡æœ‰'gate_weights'å±æ€§æˆ–è¯¥å±æ€§ä¸ºç©º")
    else:
        # ä½¿ç”¨éªŒè¯é›†åŠ è½½å¤šä¸ªæ ·æœ¬
        print("ğŸš€ ä½¿ç”¨éªŒè¯é›†åŠ è½½æ ·æœ¬...")
        if PICKLE_FILE:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ ·æœ¬æ–‡ä»¶ {PICKLE_FILE}ï¼Œæ”¹ç”¨éªŒè¯é›†")

        val_loader = dataloaders["eval"]
        sample_count = 0

        # åˆ›å»ºä¸€ä¸ªè¿›åº¦æ¡
        progress = tqdm(total=NUM_SAMPLES, desc="å¤„ç†æ ·æœ¬")

        for inputs, labels in val_loader:
            if sample_count >= NUM_SAMPLES:
                break

            # ç›´æ¥ä½¿ç”¨éªŒè¯é›†åŸå§‹ç»´åº¦é¡ºåº
            # éªŒè¯é›†è¾“å…¥å½¢çŠ¶: [batch, time, channels, height, width]
            inputs = inputs.to(device)
            print(f"ğŸ“¦ éªŒè¯é›†è¾“å…¥å¼ é‡å½¢çŠ¶: {inputs.shape}")

            # è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­
            with torch.no_grad():
                logits = net(inputs)

            # æ ¹æ®åˆ†ææ¨¡å¼è·å–é—¨æ§æƒé‡
            if ANALYSIS_MODE == 'temporal':
                # æ—¶é—´æ¨¡å¼
                if hasattr(net.temporal_transformer, 'gate_weights') and net.temporal_transformer.gate_weights:
                    gate_weights = net.temporal_transformer.gate_weights
                    print(f"âœ… [æ—¶é—´] æ£€æµ‹åˆ° {len(gate_weights)} ä¸ªé—¨æ§æƒé‡å—")

                    # å¤„ç†æ¯ä¸ªæ ·æœ¬
                    for sample_idx in range(inputs.size(0)):
                        if sample_count >= NUM_SAMPLES:
                            break

                        print(f"\nå¤„ç†æ ·æœ¬ {sample_count + 1}/{NUM_SAMPLES}")

                        for block_idx, weights_dict in enumerate(gate_weights):
                            # å¤„ç†æƒé‡æ•°æ®
                            processed_weights = process_weights(weights_dict, mode='temporal')

                            # å¯è§†åŒ–
                            plot_gate_weights(processed_weights, gate_weights_dir, block_idx, mode='temporal')

                        sample_count += 1
                        progress.update(1)
                else:
                    print("âš ï¸ è­¦å‘Š: æ—¶é—´è½¬æ¢å™¨æ²¡æœ‰'gate_weights'å±æ€§æˆ–è¯¥å±æ€§ä¸ºç©º")
                    break
            else:
                # ç©ºé—´æ¨¡å¼
                if hasattr(net.space_transformer, 'gate_weights') and net.space_transformer.gate_weights:
                    gate_weights = net.space_transformer.gate_weights
                    print(f"âœ… [ç©ºé—´] æ£€æµ‹åˆ° {len(gate_weights)} ä¸ªé—¨æ§æƒé‡å—")

                    # å¤„ç†æ¯ä¸ªæ ·æœ¬
                    for sample_idx in range(inputs.size(0)):
                        if sample_count >= NUM_SAMPLES:
                            break

                        print(f"\nå¤„ç†æ ·æœ¬ {sample_count + 1}/{NUM_SAMPLES}")

                        for block_idx, weights_dict in enumerate(gate_weights):
                            # å¤„ç†æƒé‡æ•°æ®
                            processed_weights = process_weights(weights_dict, mode='spatial')

                            # å¯è§†åŒ–
                            plot_gate_weights(processed_weights, gate_weights_dir, block_idx, mode='spatial')

                        sample_count += 1
                        progress.update(1)
                else:
                    print("âš ï¸ è­¦å‘Š: ç©ºé—´è½¬æ¢å™¨æ²¡æœ‰'gate_weights'å±æ€§æˆ–è¯¥å±æ€§ä¸ºç©º")
                    break

        progress.close()

    print("\nâœ… æ‰€æœ‰é—¨æ§æƒé‡å¯è§†åŒ–å®Œæˆï¼ç»“æœä¿å­˜åœ¨:", SAVE_DIR)
    print("=" * 50)


# --- è¿è¡Œä¸»å‡½æ•° ---
if __name__ == "__main__":
    main()