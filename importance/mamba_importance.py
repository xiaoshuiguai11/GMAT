#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é—¨æ§æƒé‡åˆ†æè„šæœ¬ - æ”¯æŒæ—¶é—´å’Œç©ºé—´ä¸¤ç§æ¨¡å¼
åˆ†ææ³¨æ„åŠ›åˆ†æ”¯å’ŒMambaåˆ†æ”¯çš„é—¨æ§æƒé‡åˆ†å¸ƒ
åˆ†æMambaå±‚çš„ä½ç½®å…³æ³¨åº¦ï¼ˆæ—¶é—´æ­¥æˆ–ç©ºé—´ä½ç½®ï¼‰
"""

import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from tqdm import tqdm
import sys
import torch.nn.functional as F
import warnings
from scipy.special import softmax
import math

# å¿½ç•¥ç‰¹å®šè­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data import get_dataloaders
from data.PASTIS24.data_transforms import Normalize
from models import get_model
from utils.config_files_utils import read_yaml
from utils.torch_utils import get_device, load_from_checkpoint

# ===========================================
# ç›´æ¥è®¾ç½®è·¯å¾„å’Œå‚æ•°
# ===========================================

CFG_PATH = r"C:\Users\Think\Desktop\DeepSatModels-main\configs\PASTIS24\TSViT_fold5.yaml"
WEIGHTS_PATH = r"C:\Users\Think\Desktop\æ¨¡å‹\logs\é—¨æ§è‡ªé€‚åº”8684\best.pth"
SAVE_DIR = r"C:\Users\Think\Desktop\gate_analysis"
PICKLE_FILE = r"C:\Users\Think\Desktop\bq\bq_new_new\kuochong_30\64\total2\20369_1_0.pickle"
NUM_SAMPLES = 5
DEVICE_IDS = [0]
ANALYSIS_MODE = 'spatial'  # å¯é€‰ 'temporal' æˆ– 'spatial'


# ===========================================
# è¾…åŠ©å‡½æ•°
# ===========================================


def custom_normalize(data, mean, std):
    """æ‰‹åŠ¨åº”ç”¨å½’ä¸€åŒ–å¤„ç†ï¼Œä¿æŒæ—¶é—´æ­¥é•¿ä¸å˜"""
    mean = mean.squeeze().astype(np.float32)
    std = std.squeeze().astype(np.float32)

    if data.ndim == 4:  # (T, C, H, W)
        mean = mean.reshape(1, -1, 1, 1)
        std = std.reshape(1, -1, 1, 1)
    elif data.ndim == 3:  # (C, H, W)
        mean = mean.reshape(-1, 1, 1)
        std = std.reshape(-1, 1, 1)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç»´åº¦: {data.ndim}")

    normalized = (data - mean) / std
    return normalized.astype(np.float32)


def prepare_model_input(normalized_img, doys):
    """
    å‡†å¤‡ç¬¦åˆæ¨¡å‹è¾“å…¥çš„å¼ é‡
    """
    doy_normalized = doys / 365.0
    doy_channel = doy_normalized[:, np.newaxis, np.newaxis, np.newaxis]
    doy_channel = np.broadcast_to(
        doy_channel,
        (doy_normalized.shape[0], 1, normalized_img.shape[2], normalized_img.shape[3])
    )

    model_input = np.concatenate([normalized_img, doy_channel], axis=1)
    return model_input.astype(np.float32)


def process_time_features(xt, device):
    """å¤„ç†æ—¶é—´ç‰¹å¾ï¼Œé¿å…ç´¢å¼•é”™è¯¯"""
    xt = torch.clamp(xt * 365.0001, 0, 365)
    xt = xt.to(torch.int64)
    max_val = xt.max().item()
    if max_val >= 366:
        print(f"âš ï¸ è­¦å‘Š: æœ€å¤§æ—¶é—´ç‰¹å¾å€¼ {max_val} è¶…è¿‡365ï¼Œå°†è¢«è£å‰ª")
        xt = torch.clamp(xt, 0, 365)
    xt = F.one_hot(xt, num_classes=366).to(torch.float32)
    return xt


# ===========================================
# é—¨æ§æƒé‡å¯è§†åŒ–å‡½æ•°
# ===========================================

def plot_gate_weights_line(gate_data, save_path):
    """
    ç»˜åˆ¶æ¯ä¸ªå—ä¸­æ³¨æ„åŠ›åˆ†æ”¯å’ŒMambaåˆ†æ”¯çš„å¹³å‡æƒé‡æŠ˜çº¿å›¾
    :param gate_data: é—¨æ§æƒé‡æ•°æ® [block_idx, attn_mean, mamba_mean]
    :param save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
    """
    plt.figure(figsize=(12, 8))

    # æå–æ•°æ®
    block_indices = [d[0] for d in gate_data]
    attn_means = [d[1] for d in gate_data]
    mamba_means = [d[2] for d in gate_data]

    # ç»˜åˆ¶æŠ˜çº¿å›¾
    plt.plot(block_indices, attn_means, marker='o', linestyle='-', color='blue', label='Attention Branch')
    plt.plot(block_indices, mamba_means, marker='s', linestyle='-', color='green', label='Mamba Branch')

    # è®¾ç½®å›¾è¡¨å±æ€§
    plt.title('å¹³å‡é—¨æ§æƒé‡éšå—å˜åŒ–è¶‹åŠ¿', fontsize=16)
    plt.xlabel('å—ç´¢å¼•', fontsize=12)
    plt.ylabel('å¹³å‡æƒé‡å€¼', fontsize=12)
    plt.xticks(block_indices)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend()

    # ä¿å­˜å›¾åƒ
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜é—¨æ§æƒé‡æŠ˜çº¿å›¾: {save_path}")


def plot_gate_weights_box(gate_data, save_path):
    """
    ç»˜åˆ¶æ¯ä¸ªå—ä¸­é—¨æ§æƒé‡çš„ç®±çº¿å›¾
    :param gate_data: é—¨æ§æƒé‡æ•°æ® [block_idx, weights]
    :param save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
    """
    plt.figure(figsize=(15, 8))

    # å‡†å¤‡ç®±çº¿å›¾æ•°æ®
    data_to_plot = []
    labels = []
    for block_idx, weights in gate_data:
        data_to_plot.append(weights)
        labels.append(f'å— {block_idx}')

    # ç»˜åˆ¶ç®±çº¿å›¾
    plt.boxplot(data_to_plot, labels=labels, showfliers=False)

    # è®¾ç½®å›¾è¡¨å±æ€§
    plt.title('é—¨æ§æƒé‡åˆ†å¸ƒéšå—å˜åŒ–', fontsize=16)
    plt.xlabel('å—ç´¢å¼•', fontsize=12)
    plt.ylabel('æƒé‡å€¼', fontsize=12)
    plt.xticks(rotation=45)
    plt.grid(True, linestyle='--', alpha=0.7)

    # ä¿å­˜å›¾åƒ
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜é—¨æ§æƒé‡ç®±çº¿å›¾: {save_path}")


def plot_single_feature_importance(block_idx, feature_imp, save_dir):
    """ä¸ºå•ä¸ªå—ç»˜åˆ¶ç‰¹å¾å…³æ³¨åº¦çƒ­åŠ›å›¾"""
    # å¦‚æœè¾“å…¥æ˜¯äºŒç»´çš„ï¼Œè®¡ç®—ç©ºé—´ä½ç½®çš„å¹³å‡å€¼
    if len(feature_imp.shape) > 1:
        print(f"ç‰¹å¾å…³æ³¨åº¦æ•°æ®ä¸ºäºŒç»´ï¼Œå½¢çŠ¶: {feature_imp.shape}ï¼Œè®¡ç®—ç©ºé—´ä½ç½®å¹³å‡")
        feature_imp = np.mean(feature_imp, axis=0)  # æ²¿ç©ºé—´ä½ç½®å¹³å‡

    print(f"å¤„ç†åçš„ç‰¹å¾å…³æ³¨åº¦æ•°æ®å½¢çŠ¶: {feature_imp.shape}")

    # åº”ç”¨softmaxå½’ä¸€åŒ–
    normalized_imp = softmax(feature_imp)

    # ç»˜åˆ¶çƒ­åŠ›å›¾
    plt.figure(figsize=(15, 4))
    sns.heatmap(
        normalized_imp.reshape(1, -1),  # ç¡®ä¿æ˜¯äºŒç»´æ•°æ®
        cmap='viridis',
        cbar=True,
        annot=False,
        yticklabels=False
    )
    plt.title(f'å— {block_idx} ç‰¹å¾å…³æ³¨åº¦')
    plt.xlabel('ç‰¹å¾ç»´åº¦')

    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f"feature_importance_block_{block_idx}.png")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜ç‰¹å¾å…³æ³¨åº¦å›¾(å— {block_idx}): {save_path}")


def plot_single_timestep_importance(block_idx, timestep_imp, save_dir):
    """ä¸ºå•ä¸ªå—ç»˜åˆ¶æ—¶é—´æ­¥å…³æ³¨åº¦çƒ­åŠ›å›¾"""
    print(f"æ—¶é—´æ­¥å…³æ³¨åº¦æ•°æ®å½¢çŠ¶: {timestep_imp.shape}")

    # å¦‚æœè¾“å…¥æ˜¯äºŒç»´çš„ï¼Œè®¡ç®—ç©ºé—´ä½ç½®çš„å¹³å‡å€¼
    if len(timestep_imp.shape) > 1:
        print(f"æ—¶é—´æ­¥å…³æ³¨åº¦æ•°æ®ä¸ºäºŒç»´ï¼Œå½¢çŠ¶: {timestep_imp.shape}ï¼Œè®¡ç®—ç©ºé—´ä½ç½®å¹³å‡")
        timestep_imp = np.mean(timestep_imp, axis=0)  # æ²¿ç©ºé—´ä½ç½®å¹³å‡

    print(f"å¤„ç†åçš„æ—¶é—´æ­¥å…³æ³¨åº¦æ•°æ®å½¢çŠ¶: {timestep_imp.shape}")

    # åº”ç”¨softmaxå½’ä¸€åŒ–
    normalized_imp = softmax(timestep_imp)
    print(f"normalized_imp shape after softmax: {normalized_imp.shape}")

    # ==============================
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    # ==============================
    plt.figure(figsize=(15, 4))
    sns.heatmap(
        normalized_imp.reshape(1, -1),  # ç¡®ä¿æ˜¯äºŒç»´æ•°æ®
        cmap='magma',
        cbar=True,
        annot=False,
        yticklabels=False
    )
    plt.title(f'å— {block_idx} æ—¶é—´æ­¥å…³æ³¨åº¦')
    plt.xlabel('æ—¶é—´æ­¥')

    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f"timestep_importance_block_{block_idx}.png")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜æ—¶é—´æ­¥å…³æ³¨åº¦å›¾(å— {block_idx}): {save_path}")


def plot_single_feature_line(block_idx, feature_imp, save_dir):
    """ä¸ºå•ä¸ªå—ç»˜åˆ¶ç‰¹å¾å…³æ³¨åº¦æŠ˜çº¿å›¾"""
    # å¦‚æœè¾“å…¥æ˜¯äºŒç»´çš„ï¼Œè®¡ç®—ç©ºé—´ä½ç½®çš„å¹³å‡å€¼
    if len(feature_imp.shape) > 1:
        print(f"ç‰¹å¾å…³æ³¨åº¦æ•°æ®ä¸ºäºŒç»´ï¼Œå½¢çŠ¶: {feature_imp.shape}ï¼Œè®¡ç®—ç©ºé—´ä½ç½®å¹³å‡")
        feature_imp = np.mean(feature_imp, axis=0)  # æ²¿ç©ºé—´ä½ç½®å¹³å‡

    print(f"å¤„ç†åçš„ç‰¹å¾å…³æ³¨åº¦æ•°æ®å½¢çŠ¶: {feature_imp.shape}")

    plt.figure(figsize=(15, 6))

    # åº”ç”¨softmaxå½’ä¸€åŒ–
    normalized_imp = softmax(feature_imp)

    # ç»˜åˆ¶æŠ˜çº¿å›¾
    plt.plot(normalized_imp, marker='o', linestyle='-', color='blue')

    # è®¾ç½®å›¾è¡¨å±æ€§
    plt.title(f'å— {block_idx} ç‰¹å¾å…³æ³¨åº¦åˆ†å¸ƒ', fontsize=16)
    plt.xlabel('ç‰¹å¾ç»´åº¦ç´¢å¼•', fontsize=12)
    plt.ylabel('å…³æ³¨åº¦å€¼', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)

    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f"feature_importance_line_block_{block_idx}.png")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜ç‰¹å¾å…³æ³¨åº¦æŠ˜çº¿å›¾(å— {block_idx}): {save_path}")


def plot_single_timestep_line(block_idx, timestep_imp, save_dir):
    """ä¸ºå•ä¸ªå—ç»˜åˆ¶æ—¶é—´æ­¥å…³æ³¨åº¦æŠ˜çº¿å›¾å¹¶ä¿å­˜CSVæ•°æ®"""
    print(f"timestep_imp shape before processing: {timestep_imp.shape}")

    # å¦‚æœè¾“å…¥æ˜¯äºŒç»´çš„ï¼Œè®¡ç®—ç©ºé—´ä½ç½®çš„å¹³å‡å€¼
    if len(timestep_imp.shape) > 1:
        print(f"æ—¶é—´æ­¥å…³æ³¨åº¦æ•°æ®ä¸ºäºŒç»´ï¼Œå½¢çŠ¶: {timestep_imp.shape}ï¼Œè®¡ç®—ç©ºé—´ä½ç½®å¹³å‡")
        timestep_imp = np.mean(timestep_imp, axis=0)  # æ²¿ç©ºé—´ä½ç½®å¹³å‡

    print(f"å¤„ç†åçš„æ—¶é—´æ­¥å…³æ³¨åº¦æ•°æ®å½¢çŠ¶: {timestep_imp.shape}")

    # åº”ç”¨softmaxå½’ä¸€åŒ–
    normalized_imp = softmax(timestep_imp)
    print(f"normalized_imp shape after softmax: {normalized_imp.shape}")

    # ==============================
    # ä¿å­˜CSVæ•°æ® (æŠ˜çº¿å›¾ä½¿ç”¨çš„å½’ä¸€åŒ–æ•°æ®)
    # ==============================
    csv_path = os.path.join(save_dir, f"timestep_importance_block_{block_idx}.csv")
    df = pd.DataFrame({
        'timestep_index': range(len(normalized_imp)),
        'normalized_importance': normalized_imp
    })
    df.to_csv(csv_path, index=False)
    print(f"âœ… ä¿å­˜æ—¶é—´æ­¥å…³æ³¨åº¦æŠ˜çº¿å›¾æ•°æ®(å— {block_idx}): {csv_path}")
    print(f"ğŸ“Š æ—¶é—´æ­¥æ•°é‡: {len(normalized_imp)}")
    print(f"ğŸ“ˆ å½’ä¸€åŒ–æ•°æ®èŒƒå›´: {normalized_imp.min():.6f} - {normalized_imp.max():.6f}")
    print(f"âˆ‘ æ¦‚ç‡æ€»å’Œ: {normalized_imp.sum():.6f}")

    # ==============================
    # ç»˜åˆ¶æŠ˜çº¿å›¾
    # ==============================
    plt.figure(figsize=(15, 6))
    plt.plot(normalized_imp, marker='s', linestyle='-', color='green')
    plt.title(f'å— {block_idx} æ—¶é—´æ­¥å…³æ³¨åº¦åˆ†å¸ƒ', fontsize=16)
    plt.xlabel('æ—¶é—´æ­¥ç´¢å¼•', fontsize=12)
    plt.ylabel('å…³æ³¨åº¦å€¼', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)

    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f"timestep_importance_line_block_{block_idx}.png")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜æ—¶é—´æ­¥å…³æ³¨åº¦æŠ˜çº¿å›¾(å— {block_idx}): {save_path}")


# ===========================================
# ç©ºé—´ä½ç½®å…³æ³¨åº¦å¯è§†åŒ–å‡½æ•°
# ===========================================

def plot_single_space_importance(block_idx, space_imp, save_dir, grid_size, patch_size, image_size):
    """
    ä¸ºå•ä¸ªå—ç»˜åˆ¶ç©ºé—´ä½ç½®å…³æ³¨åº¦çƒ­åŠ›å›¾ï¼ˆå—çº§åˆ«ï¼‰
    :param block_idx: å—ç´¢å¼•
    :param space_imp: ç©ºé—´ä½ç½®é‡è¦æ€§æ•°æ® (num_patches,)
    :param save_dir: ä¿å­˜ç›®å½•
    :param grid_size: ç½‘æ ¼å¤§å°ï¼ˆæ¯ä¸ªç»´åº¦çš„å—æ•°ï¼‰
    :param patch_size: æ¯ä¸ªå—çš„åƒç´ å¤§å°
    :param image_size: åŸå§‹å›¾åƒå°ºå¯¸
    """
    print(f"ç©ºé—´ä½ç½®å…³æ³¨åº¦æ•°æ®å½¢çŠ¶: {space_imp.shape}")

    # ç¡®ä¿ç©ºé—´ä½ç½®æ•°é‡åŒ¹é…ç½‘æ ¼å¤§å°
    expected_size = grid_size * grid_size
    if space_imp.size != expected_size:
        print(f"âš ï¸ è­¦å‘Š: ç©ºé—´ä½ç½®æ•°æ®å¤§å° {space_imp.size} ä¸é¢„æœŸç½‘æ ¼å¤§å° {expected_size} ä¸åŒ¹é…")
        return None

    # åº”ç”¨softmaxå½’ä¸€åŒ–
    normalized_imp =space_imp

    # é‡å¡‘ä¸ºäºŒç»´ç½‘æ ¼
    grid_imp = normalized_imp.reshape(grid_size, grid_size)

    # ç»˜åˆ¶çƒ­åŠ›å›¾ï¼ˆå—çº§åˆ«ï¼‰
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        grid_imp,
        cmap='viridis',
        annot=False,
        square=True,
        cbar=True,
        cbar_kws={'label': 'å…³æ³¨åº¦'}
    )
    plt.title(f'ç©ºé—´ä½ç½®å…³æ³¨åº¦ (å— {block_idx})', fontsize=16)
    plt.xlabel('X ä½ç½®', fontsize=12)
    plt.ylabel('Y ä½ç½®', fontsize=12)

    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f"space_importance_block_{block_idx}.png")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜ç©ºé—´ä½ç½®å…³æ³¨åº¦å›¾(å— {block_idx}): {save_path}")

    # ä¿å­˜CSVæ•°æ®
    csv_path = os.path.join(save_dir, f"space_importance_block_{block_idx}.csv")
    np.savetxt(csv_path, grid_imp, delimiter=",")
    print(f"âœ… ä¿å­˜ç©ºé—´ä½ç½®å…³æ³¨åº¦æ•°æ®(å— {block_idx}): {csv_path}")

    return grid_imp


def plot_pixel_importance(block_idx, grid_imp, save_dir, grid_size, patch_size, image_size):
    """
    ä¸ºå•ä¸ªå—ç»˜åˆ¶åƒç´ çº§ç©ºé—´ä½ç½®å…³æ³¨åº¦çƒ­åŠ›å›¾
    :param block_idx: å—ç´¢å¼•
    :param grid_imp: ç½‘æ ¼çº§é‡è¦æ€§æ•°æ® (grid_size, grid_size)
    :param save_dir: ä¿å­˜ç›®å½•
    :param grid_size: ç½‘æ ¼å¤§å°ï¼ˆæ¯ä¸ªç»´åº¦çš„å—æ•°ï¼‰
    :param patch_size: æ¯ä¸ªå—çš„åƒç´ å¤§å°
    :param image_size: åŸå§‹å›¾åƒå°ºå¯¸
    """
    # åˆ›å»ºå…¨å°ºå¯¸çš„é‡è¦æ€§å›¾
    pixel_imp = np.zeros((image_size, image_size))

    # è®¡ç®—æ¯ä¸ªå—å¯¹åº”çš„åƒç´ åŒºåŸŸ
    for i in range(grid_size):
        for j in range(grid_size):
            # è®¡ç®—å½“å‰å—åœ¨åŸå§‹å›¾åƒä¸­çš„åƒç´ èŒƒå›´
            start_h = i * patch_size
            end_h = min((i + 1) * patch_size, image_size)
            start_w = j * patch_size
            end_w = min((j + 1) * patch_size, image_size)

            # å°†å—çš„é‡è¦æ€§å€¼èµ‹ç»™å¯¹åº”åƒç´ åŒºåŸŸ
            pixel_imp[start_h:end_h, start_w:end_w] = grid_imp[i, j]

    # ================================
    # ç»˜åˆ¶åƒç´ çº§çƒ­åŠ›å›¾
    # ================================
    plt.figure(figsize=(12, 10))
    sns.heatmap(
        pixel_imp,
        cmap='viridis',
        annot=False,
        square=False,
        cbar=True,
        cbar_kws={'label': 'åƒç´ å…³æ³¨åº¦'}
    )
    plt.title(f'åƒç´ çº§ç©ºé—´ä½ç½®å…³æ³¨åº¦ (å— {block_idx})', fontsize=18)
    plt.xlabel('X åƒç´ ä½ç½®', fontsize=14)
    plt.ylabel('Y åƒç´ ä½ç½®', fontsize=14)

    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f"pixel_importance_block_{block_idx}.png")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜åƒç´ çº§ç©ºé—´ä½ç½®å…³æ³¨åº¦å›¾(å— {block_idx}): {save_path}")

    # ä¿å­˜CSVæ•°æ®
    csv_path = os.path.join(save_dir, f"pixel_importance_block_{block_idx}.csv")
    np.savetxt(csv_path, pixel_imp, delimiter=",")
    print(f"âœ… ä¿å­˜åƒç´ çº§ç©ºé—´ä½ç½®å…³æ³¨åº¦æ•°æ®(å— {block_idx}): {csv_path}")

    # ================================
    # è¯†åˆ«å…³é”®åƒç´ åŒºåŸŸ
    # ================================
    # æ‰¾å‡ºé‡è¦æ€§æœ€é«˜çš„åƒç´ åŒºåŸŸ
    max_imp = np.max(pixel_imp)
    threshold = max_imp * 0.7  # 70%é˜ˆå€¼
    high_imp_coords = np.argwhere(pixel_imp > threshold)

    # åˆ†æå…³é”®åŒºåŸŸ
    if len(high_imp_coords) > 0:
        print(f"ğŸ” å— {block_idx} å…³é”®åƒç´ åŒºåŸŸåˆ†æ:")
        print(f"  - é«˜å…³æ³¨åº¦åƒç´ æ•°é‡: {len(high_imp_coords)}")
        print(f"  - æœ€å¤§å…³æ³¨åº¦å€¼: {max_imp:.4f}")
        print(f"  - é«˜å…³æ³¨åº¦åŒºåŸŸè¾¹ç•Œ:")
        min_h, min_w = np.min(high_imp_coords, axis=0)
        max_h, max_w = np.max(high_imp_coords, axis=0)
        print(f"    X: {min_w}-{max_w}, Y: {min_h}-{max_h}")
        print(f"    Width: {max_w - min_w}px, Height: {max_h - min_h}px")

    return pixel_imp


def plot_space_position_importance_line(space_data, save_path):
    """
    ç»˜åˆ¶ç©ºé—´ä½ç½®å¹³å‡å…³æ³¨åº¦éšå—å˜åŒ–çš„æŠ˜çº¿å›¾
    :param space_data: ç©ºé—´ä½ç½®æ•°æ® [(block_idx, avg_importance), ...]
    :param save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
    """
    plt.figure(figsize=(12, 8))

    # æå–æ•°æ®
    block_indices = [d[0] for d in space_data]
    avg_importance = [d[1] for d in space_data]

    # ç»˜åˆ¶æŠ˜çº¿å›¾
    plt.plot(block_indices, avg_importance, marker='o', linestyle='-', color='purple', label='å¹³å‡å…³æ³¨åº¦')

    # è®¾ç½®å›¾è¡¨å±æ€§
    plt.title('ç©ºé—´ä½ç½®å¹³å‡å…³æ³¨åº¦éšå—å˜åŒ–è¶‹åŠ¿', fontsize=16)
    plt.xlabel('å—ç´¢å¼•', fontsize=12)
    plt.ylabel('å¹³å‡å…³æ³¨åº¦å€¼', fontsize=12)
    plt.xticks(block_indices)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend()

    # ä¿å­˜å›¾åƒ
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜ç©ºé—´ä½ç½®å…³æ³¨åº¦æŠ˜çº¿å›¾: {save_path}")


# ===========================================
# ä¿®æ”¹åçš„å‰å‘ä¼ æ’­å‡½æ•°ï¼ˆæ•è·é—¨æ§æƒé‡ï¼‰
# ===========================================

def modified_forward_with_gate_weights(inputs, net, analysis_mode):
    """
    ä¿®æ”¹åçš„æ¨¡å‹å‰å‘ä¼ æ’­å‡½æ•°ï¼Œæ•è·é—¨æ§æƒé‡
    è¿”å›ï¼š
    - logits: æ¨¡å‹è¾“å‡º
    - gate_weights_data: é—¨æ§æƒé‡æ•°æ® [block_idx, weights]
    """
    # æå–è¾“å…¥å½¢çŠ¶
    B, T, C, H, W = inputs.shape
    inputs = inputs.float()

    # è®¾ç½®åˆ†ææ¨¡å¼
    net.set_analysis_mode(analysis_mode)
    print(f"âœ… è®¾ç½®åˆ†ææ¨¡å¼: {analysis_mode}")

    # æå–æ—¶é—´ç‰¹å¾
    xt = inputs[:, :, -1, 0, 0]
    xt = process_time_features(xt, inputs.device)
    xt = xt.reshape(-1, 366)

    # åº”ç”¨æ—¶é—´ä½ç½®åµŒå…¥
    temporal_pos_embedding = net.to_temporal_embedding_input(xt).reshape(B, T, net.dim)

    # å‡†å¤‡patchåµŒå…¥
    x = inputs[:, :, :-1]  # ç§»é™¤æ—¶é—´ç‰¹å¾é€šé“

    # ç¡®ä¿ç©ºé—´ç»´åº¦èƒ½è¢«patch_sizeæ•´é™¤
    assert H % net.patch_size == 0, f"é«˜åº¦ {H} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"
    assert W % net.patch_size == 0, f"å®½åº¦ {W} ä¸èƒ½è¢« patch_size {net.patch_size} æ•´é™¤"

    # è®¡ç®—patchæ•°é‡
    num_patches_h = H // net.patch_size
    num_patches_w = W // net.patch_size
    num_patches = num_patches_h * num_patches_w

    # è®¡ç®—ç½‘æ ¼å¤§å°ï¼ˆç”¨äºç©ºé—´åˆ†æï¼‰
    grid_size = num_patches_h

    # æ‰‹åŠ¨å®ç°é‡æ’æ“ä½œ
    x = x.unfold(3, net.patch_size, net.patch_size)
    x = x.unfold(4, net.patch_size, net.patch_size)
    x = x.permute(0, 3, 4, 1, 2, 5, 6)
    x = x.reshape(B * num_patches_h * num_patches_w, T, 20 * net.patch_size * net.patch_size)

    # åº”ç”¨çº¿æ€§å˜æ¢
    x = net.to_patch_embedding[1](x)

    # æ·»åŠ æ—¶é—´ä½ç½®åµŒå…¥
    x = x.reshape(B, num_patches, T, net.dim)
    x += temporal_pos_embedding.unsqueeze(1)
    x = x.reshape(B * num_patches, T, net.dim)

    # æ·»åŠ æ—¶é—´token
    cls_temporal_tokens = net.temporal_token.repeat(B * num_patches, 1, 1)
    x = torch.cat((cls_temporal_tokens, x), dim=1)

    # å­˜å‚¨é—¨æ§æƒé‡æ•°æ®
    gate_weights_data = []

    # å­˜å‚¨Mambaç‰¹å¾å’Œæ—¶é—´æ­¥å…³æ³¨åº¦
    feature_importance_data = []
    timestep_importance_data = []

    # å­˜å‚¨ä½ç½®é‡è¦æ€§æ•°æ®
    position_importance_data = []

    # å¯ç”¨é—¨æ§æƒé‡æ”¶é›†
    for block in net.temporal_transformer.layers:
        # é‡ç½®Mambaåˆ†æå±æ€§
        block.feature_importance = None
        block.timestep_importance = None
        block.attention_scores = None

    # å‰å‘ä¼ æ’­æ—¶é—´å˜æ¢å™¨
    x = net.temporal_transformer(x)

    # æ”¶é›†é—¨æ§æƒé‡æ•°æ®å’ŒMambaåˆ†ææ•°æ®
    for block_idx, block in enumerate(net.temporal_transformer.layers):
        # æ”¶é›†é—¨æ§æƒé‡
        if hasattr(block, 'attn_weights') and block.attn_weights:
            # å–æœ€åä¸€æ¬¡è®°å½•çš„æƒé‡ï¼ˆå½“å‰æ‰¹æ¬¡ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œå·²ç»æ˜¯NumPyæ•°ç»„ï¼Œä¸éœ€è¦detach()
            attn_weights_np = block.attn_weights[-1].flatten()
            gate_weights_data.append((block_idx, attn_weights_np))

        # æ”¶é›†Mambaç‰¹å¾å…³æ³¨åº¦
        if hasattr(block, 'feature_importance') and block.feature_importance is not None:
            # è½¬æ¢ä¸ºNumPyæ•°ç»„
            feat_imp = block.feature_importance.detach().cpu().numpy()
            feature_importance_data.append((block_idx, feat_imp))

        # æ”¶é›†Mambaæ—¶é—´æ­¥å…³æ³¨åº¦
        if hasattr(block, 'timestep_importance') and block.timestep_importance is not None:
            # è½¬æ¢ä¸ºNumPyæ•°ç»„
            timestep_imp = block.timestep_importance.detach().cpu().numpy()
            # å»æ‰å‰4ä¸ªç±»åˆ«token (åªä¿ç•™æ—¶é—´æ­¥å…³æ³¨åº¦)
            if timestep_imp.shape[1] > 4:  # ç¡®ä¿æœ‰ç±»åˆ«token
                timestep_imp = timestep_imp[:, 4:]  # å»æ‰å‰4ä¸ªç±»åˆ«token
            timestep_importance_data.append((block_idx, timestep_imp))

    # æ”¶é›†ä½ç½®é‡è¦æ€§æ•°æ®ï¼ˆæ—¶é—´æˆ–ç©ºé—´ï¼‰
    if analysis_mode == 'temporal':
        # æ—¶é—´ä½ç½®é‡è¦æ€§
        temporal_pos_imp = net.get_temporal_position_importance()
        if temporal_pos_imp:
            print(f"âœ… æ£€æµ‹åˆ°æ—¶é—´ä½ç½®é‡è¦æ€§æ•°æ®: {len(temporal_pos_imp)} ä¸ªå—")
            for block_idx, imp in enumerate(temporal_pos_imp):
                # ç¡®ä¿æ˜¯NumPyæ•°ç»„
                if isinstance(imp, torch.Tensor):
                    imp = imp.detach().cpu().numpy()
                position_importance_data.append((block_idx, imp))
                print(f"âœ… æ”¶é›†åˆ°æ—¶é—´å— {block_idx} çš„ä½ç½®é‡è¦æ€§, å½¢çŠ¶: {imp.shape}")
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°æ—¶é—´ä½ç½®é‡è¦æ€§æ•°æ®")

    # ç©ºé—´å˜æ¢å™¨
    x = x[:, :net.num_classes]
    x = x.reshape(B, num_patches, net.num_classes, net.dim)
    x = x.permute(0, 2, 1, 3)
    x = x.reshape(B * net.num_classes, num_patches, net.dim)

    # ç¡®ä¿ç©ºé—´ä½ç½®åµŒå…¥å¤§å°åŒ¹é…
    space_pos_embedding = net.space_pos_embedding[:, :num_patches] if net.space_pos_embedding.shape[
                                                                          1] > num_patches else net.space_pos_embedding
    x += space_pos_embedding

    # åº”ç”¨dropout
    if hasattr(net, 'dropout'):
        x = net.dropout(x)

    # å‰å‘ä¼ æ’­ç©ºé—´å˜æ¢å™¨
    x = net.space_transformer(x)

    # å…³é”®ä¿®æ”¹ï¼šåœ¨ç©ºé—´å˜æ¢å™¨å‰å‘ä¼ æ’­åæ”¶é›†ç©ºé—´ä½ç½®é‡è¦æ€§æ•°æ®
    if analysis_mode == 'spatial' and hasattr(net.space_transformer, 'get_space_position_importance'):
        space_pos_imp = net.space_transformer.get_space_position_importance()
        if space_pos_imp:
            print(f"âœ… æ•è·ç©ºé—´ä½ç½®é‡è¦æ€§æ•°æ®: {len(space_pos_imp)} ä¸ªå—")
            for block_idx, imp in enumerate(space_pos_imp):
                # ç¡®ä¿æ˜¯NumPyæ•°ç»„
                if isinstance(imp, torch.Tensor):
                    imp = imp.detach().cpu().numpy()
                position_importance_data.append((block_idx, imp))
                print(f"âœ… æ”¶é›†åˆ°ç©ºé—´å— {block_idx} çš„ä½ç½®é‡è¦æ€§, å½¢çŠ¶: {imp.shape}")
        else:
            print("âš ï¸ ç©ºé—´ä½ç½®é‡è¦æ€§æ•°æ®ä¸ºç©º")

    # MLPå¤´éƒ¨
    x = net.mlp_head(x.reshape(-1, net.dim))

    # é‡å¡‘è¾“å‡º
    x = x.reshape(B, net.num_classes, num_patches, net.patch_size ** 2)
    x = x.permute(0, 2, 3, 1)
    x = x.reshape(B, num_patches_h, num_patches_w, net.patch_size, net.patch_size, net.num_classes)
    x = x.permute(0, 1, 3, 2, 4, 5)
    x = x.reshape(B, num_patches_h * net.patch_size, num_patches_w * net.patch_size, net.num_classes)
    x = x.permute(0, 3, 1, 2)

    return x, gate_weights_data, feature_importance_data, timestep_importance_data, position_importance_data, grid_size


# ===========================================
# è®¡ç®—å¹¶ä¿å­˜ç©ºé—´patchå—é‡è¦æ€§
# ===========================================

def save_spatial_patch_importance(position_importance_data, save_dir, num_patches):
    """
    ä¸ºæ¯ä¸€å±‚Transformerè®¡ç®—å¹¶ä¿å­˜ç©ºé—´patchå—çš„é‡è¦æ€§å‘é‡
    :param position_importance_data: ä½ç½®é‡è¦æ€§æ•°æ®åˆ—è¡¨ [(block_idx, importance_vector), ...]
    :param save_dir: ä¿å­˜ç›®å½•
    :param num_patches: ç©ºé—´patchå—æ•°é‡
    """
    # åˆ›å»ºæ±‡æ€»DataFrame
    summary_df = pd.DataFrame()

    # ä¸ºæ¯ä¸€å±‚ä¿å­˜å•ç‹¬çš„æ–‡ä»¶
    for block_idx, imp_vec in position_importance_data:
        # ç¡®ä¿å‘é‡é•¿åº¦æ­£ç¡®
        if len(imp_vec) < num_patches:
            # ç”¨0å¡«å……ä¸è¶³éƒ¨åˆ†
            padded_vec = np.zeros(num_patches)
            padded_vec[:len(imp_vec)] = imp_vec
            imp_vec = padded_vec
            print(f"âš ï¸ å— {block_idx} é‡è¦æ€§å‘é‡é•¿åº¦ä¸è¶³ {num_patches}ï¼Œå·²ç”¨0å¡«å……")
        elif len(imp_vec) > num_patches:
            # æˆªæ–­è¶…è¿‡éƒ¨åˆ†
            imp_vec = imp_vec[:num_patches]
            print(f"âš ï¸ å— {block_idx} é‡è¦æ€§å‘é‡é•¿åº¦è¶…è¿‡ {num_patches}ï¼Œå·²æˆªæ–­")

        # åˆ›å»ºDataFrameä¿å­˜å½“å‰å—çš„é‡è¦æ€§
        df = pd.DataFrame({
            'patch_index': range(num_patches),
            'importance': imp_vec
        })

        # ä¿å­˜å½“å‰å—çš„CSV
        csv_path = os.path.join(save_dir, f"spatial_patch_importance_block_{block_idx}.csv")
        df.to_csv(csv_path, index=False)
        print(f"âœ… ä¿å­˜å— {block_idx} çš„ç©ºé—´patché‡è¦æ€§: {csv_path}")

        # æ·»åŠ åˆ°æ±‡æ€»DataFrame
        summary_df[f'block_{block_idx}'] = imp_vec

    # ä¿å­˜æ±‡æ€»CSV
    if not summary_df.empty:
        summary_df.insert(0, 'patch_index', range(num_patches))
        summary_csv_path = os.path.join(save_dir, "spatial_patch_importance_summary.csv")
        summary_df.to_csv(summary_csv_path, index=False)
        print(f"âœ… ä¿å­˜ç©ºé—´patché‡è¦æ€§æ±‡æ€»: {summary_csv_path}")
    else:
        print("âš ï¸ æœªç”Ÿæˆç©ºé—´patché‡è¦æ€§æ±‡æ€»æ–‡ä»¶ï¼Œæ— æœ‰æ•ˆæ•°æ®")


# ===========================================
# ä¸»å‡½æ•°
# ===========================================

def main():
    global ANALYSIS_MODE

    print("=" * 50)
    print(f"æ¨¡å‹é…ç½®æ–‡ä»¶: {CFG_PATH}")
    print(f"æ¨¡å‹æƒé‡æ–‡ä»¶: {WEIGHTS_PATH}")
    print(f"ç»“æœä¿å­˜ç›®å½•: {SAVE_DIR}")
    print(f"ä½¿ç”¨è®¾å¤‡: {'GPU' if DEVICE_IDS else 'CPU'} {DEVICE_IDS}")
    print(f"åˆ†ææ¨¡å¼: {ANALYSIS_MODE}")
    print("=" * 50)

    # 0. è®¾å¤‡è®¾ç½®
    device = get_device(DEVICE_IDS, allow_cpu=True)

    # 1. åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(SAVE_DIR, exist_ok=True)

    # æ ¹æ®åˆ†ææ¨¡å¼åˆ›å»ºä¸»ç›®å½•
    if ANALYSIS_MODE == 'temporal':
        main_dir = os.path.join(SAVE_DIR, "temporal_analysis")
    elif ANALYSIS_MODE == 'spatial':
        main_dir = os.path.join(SAVE_DIR, "spatial_analysis")
    else:
        raise ValueError(f"æ— æ•ˆçš„åˆ†ææ¨¡å¼: {ANALYSIS_MODE}")

    os.makedirs(main_dir, exist_ok=True)
    print(f"ğŸ“ ä¸»åˆ†æç›®å½•: {main_dir}")

    # åˆ›å»ºå­ç›®å½•
    gate_dir = os.path.join(main_dir, "gate_weights_analysis")
    feature_dir = os.path.join(main_dir, "feature_importance")
    timestep_dir = os.path.join(main_dir, "timestep_importance")
    position_dir = os.path.join(main_dir, "position_importance")
    patch_importance_dir = os.path.join(main_dir, "patch_importance")  # æ–°å¢ç›®å½•

    # ç¡®ä¿æ‰€æœ‰ç›®å½•éƒ½å­˜åœ¨
    os.makedirs(gate_dir, exist_ok=True)
    os.makedirs(feature_dir, exist_ok=True)
    os.makedirs(timestep_dir, exist_ok=True)
    os.makedirs(position_dir, exist_ok=True)
    os.makedirs(patch_importance_dir, exist_ok=True)  # ç¡®ä¿æ–°ç›®å½•å­˜åœ¨

    # 2. è¯»å–é…ç½®
    config = read_yaml(CFG_PATH)
    config["local_device_ids"] = DEVICE_IDS

    # 3. åˆ›å»ºä¸´æ—¶dataloaderä»¥è·å–å½’ä¸€åŒ–å‚æ•°
    print("ğŸ“Š ç»Ÿè®¡è®­ç»ƒé›†å‡å€¼ / æ ‡å‡†å·® ...")
    dataloaders = get_dataloaders(config)

    # 4. è·å–å½’ä¸€åŒ–å‚æ•°
    normalize_obj = None
    for t in dataloaders["train"].dataset.transform.transforms:
        if isinstance(t, Normalize):
            t.compute_stats = True
            normalize_obj = t
            break

    if normalize_obj is None:
        raise RuntimeError("Normalize å®ä¾‹æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ transform åˆ—è¡¨ã€‚")

    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    with torch.no_grad():
        for _ in tqdm(dataloaders["train"], desc="è®¡ç®—å‡å€¼/æ ‡å‡†å·®"):
            pass
    normalize_obj.compute_mean_std()
    normalize_obj.compute_stats = False

    # è·å–å‡å€¼å’Œæ ‡å‡†å·®
    mean = normalize_obj.mean.numpy().squeeze()
    std = normalize_obj.std.numpy().squeeze()
    print(f"âœ… å½’ä¸€åŒ–ç»Ÿè®¡å®Œæˆ: mean={mean}, std={std}")

    # 5. æ„å»ºå¹¶åŠ è½½æ¨¡å‹
    print("ğŸ”§ æ„å»ºå¹¶åŠ è½½æ¨¡å‹...")
    net = get_model(config, device)
    load_from_checkpoint(net, WEIGHTS_PATH, device)
    net.to(device).eval()

    # è·å–æ¨¡å‹å‚æ•°
    patch_size = getattr(net, 'patch_size', 16)
    print(f"â„¹ï¸ ä½¿ç”¨patch_size: {patch_size}")

    # 6. åŠ è½½æ ·æœ¬æ•°æ®
    if PICKLE_FILE and os.path.exists(PICKLE_FILE):
        print(f"ğŸš€ åŠ è½½æ ·æœ¬: {PICKLE_FILE}")
        with open(PICKLE_FILE, 'rb') as f:
            data = pickle.load(f)
        img_data, labels, doys = data['img'], data['labels'], data['doy']

        # æ‰“å°åŸå§‹å½¢çŠ¶ä¿¡æ¯
        print(
            f"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶ - æ—¶é—´æ­¥: {img_data.shape[0]}, é€šé“: {img_data.shape[1]}, ç©ºé—´: {img_data.shape[2]}x{img_data.shape[3]}")

        # åº”ç”¨è‡ªå®šä¹‰å½’ä¸€åŒ–
        normalized_img = custom_normalize(img_data, mean, std)

        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        model_input = prepare_model_input(normalized_img, doys)

        # æ‰“å°è°ƒæ•´åçš„å½¢çŠ¶
        T, C, H, W = model_input.shape
        print(f"ğŸ”„ æ¨¡å‹è¾“å…¥å½¢çŠ¶ - æ—¶é—´æ­¥: {T}, é€šé“: {C}, ç©ºé—´: {H}x{W}")
        print(f"â„¹ï¸ ç©ºé—´ç»´åº¦ {H}x{W} åº”èƒ½è¢« {patch_size} æ•´é™¤: {H % patch_size == 0 and W % patch_size == 0}")

        # è®¡ç®—ç©ºé—´patchå—æ•°é‡
        num_patches_h = H // patch_size
        num_patches_w = W // patch_size
        num_patches = num_patches_h * num_patches_w
        print(f"â„¹ï¸ ç©ºé—´patchå—æ•°é‡: {num_patches} ({num_patches_h}x{num_patches_w})")

        # è½¬æ¢ä¸ºå¼ é‡å¹¶è°ƒæ•´ç»´åº¦é¡ºåº
        inputs = torch.tensor(model_input, dtype=torch.float32)
        inputs = inputs.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ [1, T, C, H, W]
        inputs = inputs.to(device)
        print(f"ğŸ“¦ è¾“å…¥å¼ é‡å½¢çŠ¶: {inputs.shape}")

        # è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­ - æ•è·é—¨æ§æƒé‡å’ŒMambaåˆ†ææ•°æ®
        print("è¿è¡Œæ¨¡å‹å‰å‘ä¼ æ’­å¹¶æ•è·åˆ†ææ•°æ®...")
        with torch.no_grad():
            logits, gate_weights_data, feature_importance_data, timestep_importance_data, position_importance_data, grid_size = \
                modified_forward_with_gate_weights(inputs, net, ANALYSIS_MODE)

        # å¤„ç†é—¨æ§æƒé‡æ•°æ®
        if gate_weights_data:
            print(f"âœ… æ£€æµ‹åˆ° {len(gate_weights_data)} ä¸ªå—çš„é—¨æ§æƒé‡")

            # å‡†å¤‡æŠ˜çº¿å›¾æ•°æ®
            line_plot_data = []
            for block_idx, weights in gate_weights_data:
                attn_mean = np.mean(weights)  # æ³¨æ„åŠ›åˆ†æ”¯å¹³å‡æƒé‡
                mamba_mean = 1 - attn_mean  # Mambaåˆ†æ”¯å¹³å‡æƒé‡
                line_plot_data.append((block_idx, attn_mean, mamba_mean))

            # ç»˜åˆ¶æŠ˜çº¿å›¾
            line_path = os.path.join(gate_dir, "gate_weights_line.png")
            plot_gate_weights_line(line_plot_data, line_path)

            # ç»˜åˆ¶ç®±çº¿å›¾
            box_path = os.path.join(gate_dir, "gate_weights_box.png")
            plot_gate_weights_box(gate_weights_data, box_path)

            # ä¿å­˜CSVæ•°æ®
            for block_idx, weights in gate_weights_data:
                print(f"Saving gate weights for block {block_idx}, weights shape: {weights.shape}")
                csv_path = os.path.join(gate_dir, f"gate_weights_block_{block_idx}.csv")
                pd.DataFrame(weights, columns=['weight']).to_csv(csv_path, index=False)
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°é—¨æ§æƒé‡æ•°æ®ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ç»“æ„")

        # å¤„ç†Mambaç‰¹å¾å…³æ³¨åº¦æ•°æ®
        if feature_importance_data:
            print(f"âœ… æ£€æµ‹åˆ° {len(feature_importance_data)} ä¸ªå—çš„ç‰¹å¾å…³æ³¨åº¦")

            # ä¸ºæ¯ä¸ªå—å•ç‹¬ç»˜åˆ¶ç‰¹å¾å…³æ³¨åº¦å›¾
            for block_idx, feat_imp in feature_importance_data:
                # ç»˜åˆ¶çƒ­åŠ›å›¾
                plot_single_feature_importance(block_idx, feat_imp, feature_dir)

                # ç»˜åˆ¶æŠ˜çº¿å›¾
                plot_single_feature_line(block_idx, feat_imp, feature_dir)

                # ä¿å­˜CSVæ•°æ®
                csv_path = os.path.join(feature_dir, f"feature_importance_block_{block_idx}.csv")
                pd.DataFrame(feat_imp).to_csv(csv_path, index=False)
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°Mambaç‰¹å¾å…³æ³¨åº¦æ•°æ®")

        # å¤„ç†Mambaæ—¶é—´æ­¥å…³æ³¨åº¦æ•°æ®
        if timestep_importance_data:
            print(f"âœ… æ£€æµ‹åˆ° {len(timestep_importance_data)} ä¸ªå—çš„æ—¶é—´æ­¥å…³æ³¨åº¦")

            # ä¸ºæ¯ä¸ªå—å•ç‹¬ç»˜åˆ¶æ—¶é—´æ­¥å…³æ³¨åº¦å›¾
            for block_idx, time_imp in timestep_importance_data:
                # ç»˜åˆ¶çƒ­åŠ›å›¾
                plot_single_timestep_importance(block_idx, time_imp, timestep_dir)

                # ç»˜åˆ¶æŠ˜çº¿å›¾å¹¶ä¿å­˜CSV
                plot_single_timestep_line(block_idx, time_imp, timestep_dir)
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°Mambaæ—¶é—´æ­¥å…³æ³¨åº¦æ•°æ®")

        # å¤„ç†ä½ç½®é‡è¦æ€§æ•°æ®
        if position_importance_data:
            print(f"âœ… æ£€æµ‹åˆ° {len(position_importance_data)} ä¸ªå—çš„ä½ç½®é‡è¦æ€§")

            # æ—¶é—´æ¨¡å¼ï¼šç»˜åˆ¶æ—¶é—´æ­¥å…³æ³¨åº¦æŠ˜çº¿å›¾
            if ANALYSIS_MODE == 'temporal':
                for block_idx, pos_imp in position_importance_data:
                    plot_single_timestep_line(block_idx, pos_imp, position_dir)

            # ç©ºé—´æ¨¡å¼ï¼šå¤„ç†ç©ºé—´ä½ç½®é‡è¦æ€§
            elif ANALYSIS_MODE == 'spatial':
                # ä¿å­˜ç©ºé—´patchå—é‡è¦æ€§
                save_spatial_patch_importance(
                    position_importance_data=position_importance_data,
                    save_dir=patch_importance_dir,
                    num_patches=num_patches
                )

                # ç»˜åˆ¶ç©ºé—´ä½ç½®çƒ­åŠ›å›¾
                line_plot_data = []
                for block_idx, pos_imp in position_importance_data:
                    # ç»˜åˆ¶ç©ºé—´ä½ç½®çƒ­åŠ›å›¾ï¼ˆå—çº§åˆ«ï¼‰
                    grid_imp = plot_single_space_importance(
                        block_idx=block_idx,
                        space_imp=pos_imp,
                        save_dir=position_dir,
                        grid_size=grid_size,
                        patch_size=patch_size,
                        image_size=H  # ä½¿ç”¨åŸå§‹å›¾åƒé«˜åº¦
                    )

                    # ç»˜åˆ¶åƒç´ çº§çƒ­åŠ›å›¾
                    if grid_imp is not None:
                        pixel_imp = plot_pixel_importance(
                            block_idx=block_idx,
                            grid_imp=grid_imp,
                            save_dir=position_dir,
                            grid_size=grid_size,
                            patch_size=patch_size,
                            image_size=H  # ä½¿ç”¨åŸå§‹å›¾åƒé«˜åº¦
                        )

                    # è®¡ç®—å¹³å‡å…³æ³¨åº¦ç”¨äºæŠ˜çº¿å›¾
                    avg_imp = np.mean(pos_imp)
                    line_plot_data.append((block_idx, avg_imp))

                # ç»˜åˆ¶ç©ºé—´ä½ç½®å¹³å‡å…³æ³¨åº¦æŠ˜çº¿å›¾
                if line_plot_data:
                    line_path = os.path.join(position_dir, "space_importance_trend.png")
                    plot_space_position_importance_line(line_plot_data, line_path)
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ä½ç½®é‡è¦æ€§æ•°æ®")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æ ·æœ¬æ–‡ä»¶ {PICKLE_FILE}ï¼Œè¯·æ£€æŸ¥è·¯å¾„")

    print("\nâœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨:", main_dir)
    print("=" * 50)


if __name__ == "__main__":
    main()